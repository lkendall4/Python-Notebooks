{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Identify and Gather Tweets (done outside of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Gather Tweets mentioning Candidates - see Tweet Gathering Python Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Score each tweet for Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a - Import Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#input_file = 'c:/Users/kmentzer/desktop/electiononly_tweets.csv'\n",
    "# If restarting process then load this file which has the data up through step 4.\n",
    "input_file = 'D:/Data/Politics2020/V3/TrimmedComb.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(input_file, header = 0, usecols = ['TweetDate','Hashtags','TweetID','Tweet','Gender','Retweet','PolarityV2','Party'])\n",
    "#data = pd.read_csv(input_file, header = 0, usecols = ['TweetDate','Hashtags','TweetID','Tweet','Gender','Retweet','PolarityV2','Party'], nrows = 5)\n",
    "#data = pd.read_csv(input_file, header = None, nrows = 5)\n",
    "data = pd.read_csv(input_file, header = None)\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head()) # Take a look at what we have - this will give us start date\n",
    "#print(df.tail()) # This will give us end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give ourselves some better labels\n",
    "df.columns = ['Hashtags','TweetID','TweetDate','Text','Name','User','UserID','UserLoc','UserDesc','UserFollowers','UserFriends','UserListed','UserCreated','UserFavs','UserVerified','UserStatuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>Text</th>\n",
       "      <th>Name</th>\n",
       "      <th>User</th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserLoc</th>\n",
       "      <th>UserDesc</th>\n",
       "      <th>UserFollowers</th>\n",
       "      <th>UserFriends</th>\n",
       "      <th>UserListed</th>\n",
       "      <th>UserCreated</th>\n",
       "      <th>UserFavs</th>\n",
       "      <th>UserVerified</th>\n",
       "      <th>UserStatuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163585806336</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶</td>\n",
       "      <td>ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è</td>\n",
       "      <td>NinerNabs49</td>\n",
       "      <td>1904396719</td>\n",
       "      <td>NorCal</td>\n",
       "      <td>Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020</td>\n",
       "      <td>3410</td>\n",
       "      <td>912</td>\n",
       "      <td>65</td>\n",
       "      <td>Wed Sep 25 14:10:01 +0000 2013</td>\n",
       "      <td>43871</td>\n",
       "      <td>False</td>\n",
       "      <td>41225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163548012546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶</td>\n",
       "      <td>Joni Skibo/LaCroix</td>\n",
       "      <td>Joni_Looking</td>\n",
       "      <td>857936728165896204</td>\n",
       "      <td>Homes in MI &amp; FL</td>\n",
       "      <td>VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 &amp; S2006\\r\\n&amp;Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic &amp; Design Quilts</td>\n",
       "      <td>5382</td>\n",
       "      <td>3863</td>\n",
       "      <td>28</td>\n",
       "      <td>Fri Apr 28 12:37:10 +0000 2017</td>\n",
       "      <td>493141</td>\n",
       "      <td>False</td>\n",
       "      <td>829357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163778748417</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶</td>\n",
       "      <td>I Stand 4 Life</td>\n",
       "      <td>Stand4AllLife</td>\n",
       "      <td>859812116227735552</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>#ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com</td>\n",
       "      <td>1838</td>\n",
       "      <td>3413</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 03 16:49:17 +0000 2017</td>\n",
       "      <td>25296</td>\n",
       "      <td>False</td>\n",
       "      <td>25012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163845996546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶</td>\n",
       "      <td>üíô Tonia üíô</td>\n",
       "      <td>ToniaJohns18</td>\n",
       "      <td>1218658110526689280</td>\n",
       "      <td>MN USA</td>\n",
       "      <td>üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§</td>\n",
       "      <td>8247</td>\n",
       "      <td>8510</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat Jan 18 22:15:47 +0000 2020</td>\n",
       "      <td>35670</td>\n",
       "      <td>False</td>\n",
       "      <td>13340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163787268096</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>@JRehling @realDonaldTrump Wait a minute, did he just admit he just CRASHED!!  I don't think I've heard Joe say any‚Ä¶ https://t.co/2HFAvKuxlX</td>\n",
       "      <td>James Huff</td>\n",
       "      <td>JamesHu40978214</td>\n",
       "      <td>1221181060773564418</td>\n",
       "      <td>Leland, NC</td>\n",
       "      <td>I Love the Lord Jesus Christ with all my Heart ‚ô•Ô∏è</td>\n",
       "      <td>362</td>\n",
       "      <td>564</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jan 25 21:20:40 +0000 2020</td>\n",
       "      <td>12363</td>\n",
       "      <td>False</td>\n",
       "      <td>10099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hashtags              TweetID                       TweetDate  \\\n",
       "0       []  1302995163585806336  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1       []  1302995163548012546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "2       []  1302995163778748417  Mon Sep 07 15:40:30 +0000 2020   \n",
       "3       []  1302995163845996546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "4       []  1302995163787268096  Mon Sep 07 15:40:30 +0000 2020   \n",
       "\n",
       "                                                                                                                                           Text  \\\n",
       "0   RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶   \n",
       "1  RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶   \n",
       "2  RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶   \n",
       "3   RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶   \n",
       "4  @JRehling @realDonaldTrump Wait a minute, did he just admit he just CRASHED!!  I don't think I've heard Joe say any‚Ä¶ https://t.co/2HFAvKuxlX   \n",
       "\n",
       "                            Name             User               UserID  \\\n",
       "0  ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è      NinerNabs49           1904396719   \n",
       "1             Joni Skibo/LaCroix     Joni_Looking   857936728165896204   \n",
       "2                 I Stand 4 Life    Stand4AllLife   859812116227735552   \n",
       "3                      üíô Tonia üíô     ToniaJohns18  1218658110526689280   \n",
       "4                     James Huff  JamesHu40978214  1221181060773564418   \n",
       "\n",
       "            UserLoc  \\\n",
       "0            NorCal   \n",
       "1  Homes in MI & FL   \n",
       "2        Irvine, CA   \n",
       "3            MN USA   \n",
       "4        Leland, NC   \n",
       "\n",
       "                                                                                                                                                                                UserDesc  \\\n",
       "0                                                   Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020   \n",
       "1  VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 & S2006\\r\\n&Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic & Design Quilts   \n",
       "2                                            #ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com   \n",
       "3                           üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§   \n",
       "4                                                                                                                                      I Love the Lord Jesus Christ with all my Heart ‚ô•Ô∏è   \n",
       "\n",
       "   UserFollowers  UserFriends  UserListed                     UserCreated  \\\n",
       "0           3410          912          65  Wed Sep 25 14:10:01 +0000 2013   \n",
       "1           5382         3863          28  Fri Apr 28 12:37:10 +0000 2017   \n",
       "2           1838         3413           1  Wed May 03 16:49:17 +0000 2017   \n",
       "3           8247         8510           4  Sat Jan 18 22:15:47 +0000 2020   \n",
       "4            362          564           2  Sat Jan 25 21:20:40 +0000 2020   \n",
       "\n",
       "   UserFavs  UserVerified  UserStatuses  \n",
       "0     43871         False         41225  \n",
       "1    493141         False        829357  \n",
       "2     25296         False         25012  \n",
       "3     35670         False         13340  \n",
       "4     12363         False         10099  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hashtags              TweetID                       TweetDate  \\\n",
      "0       []  1302995163585806336  Mon Sep 07 15:40:30 +0000 2020   \n",
      "1       []  1302995163548012546  Mon Sep 07 15:40:30 +0000 2020   \n",
      "2       []  1302995163778748417  Mon Sep 07 15:40:30 +0000 2020   \n",
      "3       []  1302995163845996546  Mon Sep 07 15:40:30 +0000 2020   \n",
      "4       []  1302995163787268096  Mon Sep 07 15:40:30 +0000 2020   \n",
      "\n",
      "                                                                                                                                           Text  \\\n",
      "0   RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶   \n",
      "1  RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶   \n",
      "2  RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶   \n",
      "3   RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶   \n",
      "4  @JRehling @realDonaldTrump Wait a minute, did he just admit he just CRASHED!!  I don't think I've heard Joe say any‚Ä¶ https://t.co/2HFAvKuxlX   \n",
      "\n",
      "                            Name             User               UserID  \\\n",
      "0  ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è      NinerNabs49           1904396719   \n",
      "1             Joni Skibo/LaCroix     Joni_Looking   857936728165896204   \n",
      "2                 I Stand 4 Life    Stand4AllLife   859812116227735552   \n",
      "3                      üíô Tonia üíô     ToniaJohns18  1218658110526689280   \n",
      "4                     James Huff  JamesHu40978214  1221181060773564418   \n",
      "\n",
      "            UserLoc  \\\n",
      "0            NorCal   \n",
      "1  Homes in MI & FL   \n",
      "2        Irvine, CA   \n",
      "3            MN USA   \n",
      "4        Leland, NC   \n",
      "\n",
      "                                                                                                                                                                                UserDesc  \\\n",
      "0                                                   Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020   \n",
      "1  VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 & S2006\\r\\n&Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic & Design Quilts   \n",
      "2                                            #ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com   \n",
      "3                           üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§   \n",
      "4                                                                                                                                      I Love the Lord Jesus Christ with all my Heart ‚ô•Ô∏è   \n",
      "\n",
      "   UserFollowers  UserFriends  UserListed                     UserCreated  \\\n",
      "0           3410          912          65  Wed Sep 25 14:10:01 +0000 2013   \n",
      "1           5382         3863          28  Fri Apr 28 12:37:10 +0000 2017   \n",
      "2           1838         3413           1  Wed May 03 16:49:17 +0000 2017   \n",
      "3           8247         8510           4  Sat Jan 18 22:15:47 +0000 2020   \n",
      "4            362          564           2  Sat Jan 25 21:20:40 +0000 2020   \n",
      "\n",
      "   UserFavs  UserVerified  UserStatuses  \n",
      "0     43871         False         41225  \n",
      "1    493141         False        829357  \n",
      "2     25296         False         25012  \n",
      "3     35670         False         13340  \n",
      "4     12363         False         10099  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) # This will make it so all columns appear when printing\n",
    "pd.options.display.max_colwidth = 300  # This makes it so we can see the entire tweet text.\n",
    "pd.set_option('display.max_rows', 100)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp0 = df.groupby(['Gender2','Retweet']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp0 = df.groupby(['Party', 'Retweet']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = df.groupby(['Party','Manchin']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0b = df.groupby(['Party','Gender2','Retweet','DaysToElection']).agg({'DaysToElection': ['count']})\n",
    "print(temp0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures not in paper\n",
    "#temp1  = df.groupby(['Party','Gender_Mentioned','PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "# Figure 3a\n",
    "#temp1 = df.groupby(['Party','Gender2','PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "\n",
    "# Figure 4\n",
    "#temp1 = df.groupby(['Gender2','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "\n",
    "# Figure 5\n",
    "#temp1 = df.groupby(['Party','Gender2','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "\n",
    "# Figure 6\n",
    "#temp1 = df.groupby(['Party','Gender2','Gender_Mentioned', 'PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "#temp1 = df.groupby(['Party','PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "\n",
    "temp1 = df.groupby(['Retweet']).agg({'Polarity': ['mean', 'std', 'count']})\n",
    "\n",
    "print(temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with new data 9/11/19\n",
    "#temp1c = df.groupby(['Party','Gender2','DaysToElection']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "#temp1c = df.groupby(['Party','Gender2','PartyMentioned','DaysToElection']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "#temp1c = df.groupby(['Party','Gender2','PartyMentioned','PolarityCluster','DaysToElection']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp1c = df.groupby(['Party','PartyMentioned','DaysToElection']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "\n",
    "\n",
    "print(temp1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1c.to_csv('D:\\Politics\\PartyPartyDaily.csv', header=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = df.groupby(['Party','Gen','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give ourselves some better lables\n",
    "df.columns = ['TweetDate','Hashtags','TweetID','TwitterDate','Tweet','UserName','User','UserID','UserLoc','UserNote','j1','j2','j3','j4','j5','j6','j7','FirstName','LastName','Gender','Polarity','Subjectivity','Sentiment','fcandidate','mcandidate','fcand2','mcand2']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the columns we don't need\n",
    "df = df.drop(['j1', 'j2', 'j3','j4','j5','j6','j7','fcand2','mcand2', 'UserName', 'TwitterDate'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b - Filter tweets down to 6 week period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c - Strip punctuation from Tweet text and convert to all lower case (so \"Happy!\" is the same as \"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "tlist = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    out = row['Text'].translate(str.maketrans('', '', string.punctuation))\n",
    "    out = out.lower()\n",
    "    tlist.append(out)\n",
    "\n",
    "df['CleanTweet'] = tlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Classify whether a tweet mentions Male Candidate only, Female Candidate Only, Both (or neither)\n",
    "\n",
    "We are doing step 6 here so we can remove those tweets where no candidate is mentined in the tweet text. This happens because twitter looks at more than just the tweet text for a keyword match, so we might have tweets that the tweet text itself mentions no candidate (and we aren't interested in those). We can then filter these down and this becomes our starting N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_flag = []\n",
    "m_flag = []\n",
    "gender_flag = []\n",
    "lv_f = 0\n",
    "lv_m = 0\n",
    "\n",
    "# 2018 Data\n",
    "#female_candidates = ['eveforussenate','repmcsally','kyrstensinema','senfeinstein','diannefeinstein','maziehirono','lucy4senate','senwarren','stabenow', 'amyklobuchar','clairecmc','senatorfischer','janeraybould','repjackyrosen','newdayfornj','hoffman4us2018','voterivera','chelefarley','sengillibrand','senatorheitkamp','marshablackburn','jennywilsonut','mariacantwell','susan_hutch','senatorbaldwin','leahvukmir','hillaryclinton'] # List all the female candidates here\n",
    "#male_candidates = ['adamkokesh','kdeleon','mattcoreyct','chrismurphyct','robarlett', 'senatorcarper', 'senbillnelson', 'flgovscott','rcurtis808','braun4indiana','joeforindiana','senatorbrakey','senangusking','ringelsteinme','campbell4md','senatorcardin','nealjsimon','senatorshlikas','votevohra','va_shiva','diehlforsenate','repgeoffdiehl','johnjamesmi','newbergerjim','dbaria','bedwell_guy','senatorwicker','yefeth','hawleymo','drbreckenridge','mattformontana','senatortester','senatejim','trexhagan','deanheller','barry4ussenate','bobhugin','senatormenendez','kfkimple','msabrin','govgaryjohnson','martinheinrich','mickrich4senate','repkevincramer','sensherrodbrown','repjimrenacci','reploubarletta','senbobcasey','flanders4senate','senwhitehouse','philbredesen','tedcruz','nealdikeman','betoorourke','bowden4senate','mccandlessreed','mittromney','sensanders','timkaine','coreystewartva','vasenate2018','sen_joemanchin','morriseywv','senjohnbarrasso','dodsonforsenate','traunerforwy','realdonaldtrump']   # List all the male candidate here\n",
    "\n",
    "#2020 Data\n",
    "female_candidates = ['marthamcsally','jessfordelaware','witzkeforde','senatorloeffler','electpaulette','senjoniernst','herzog4alliowa','greenfieldiowa','barbarabollier','amymcgrathky','senatorcollins','saragideon','sentinasmith','cindyhydesmith','shelton4senate','jeanneshaheen','hoffman4us2020','veronicafornj','abbybroyles','perkinsforussen','bradshaw2020','mjhegar','paulajean2020','sencapito','mbendavid2020','cynthiamlummis']\n",
    "male_candidates = ['dougjoneshq','ttuberville','dralgrossak','dansullivan_ak','captmarkkelly','sentomcotton','rdh4senate','danwhitcongress','sencorygardner','hickenlooper','doaneraymon','chriscoons','jimdemartino','sendavidperdue','ossoff','shanethazel','jononsenate','collinsforga','liebermanforga','reverendwarnock','risch4idaho','senatordurbin','electmarkcurran','dannymalouf2020','drwilliewilson','rickstewart','jbuckley2020','rogermarshallmd','team_mitch','barron_ky','billcassidy','d_edwardsla','ddrewknight','perkinsforla','antoinepierce','wenstrupforla','dustinforsenate','docmontyfor2020','edmarkey','joekennedy','va_shiva','kocforsenate','garypeters','johnjamesmi','lewisformn','mikeespy','dainesformt','stevebullockmt','bensasse','cjsenate2020','tomalciere','gerardbeloin','gendonbolduc','andymartinusa','corkyforsenate','odonnell4nh','corybooker','rikmehta_nj','burke4senate','benraylujan','markronchettinm','senthomtillis','calfornc','shannonbraync','inhofeforsenate','senjeffmerkley','jackreed2020','allenrwaters','lindseygrahamsc','harrisonjaime','senatorrounds','ahlers_dan','billhagertytn','teamcornyn','mckennon2020','dbcgreentx','markwarner','gadeforvirginia']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tweet = row['CleanTweet']\n",
    "    tweet = str(tweet).lower()\n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in female_candidates):\n",
    "            f_flag.append(1)\n",
    "            lv_f = 1\n",
    "        else:\n",
    "            f_flag.append(0)\n",
    "            lv_f = 0\n",
    "    except:\n",
    "        f_flag.append(0)\n",
    "        lv_f = 0\n",
    "        \n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in male_candidates):\n",
    "            m_flag.append(1)\n",
    "            lv_m = 1\n",
    "        else:\n",
    "            m_flag.append(0)\n",
    "            lv_m = 0\n",
    "    except:\n",
    "        m_flag.append(0)\n",
    "        lv_m = 0\n",
    "\n",
    "    if lv_f == 1 and lv_m == 1:\n",
    "        gender_flag.append('B')\n",
    "    elif lv_f == 1:\n",
    "        gender_flag.append('F')\n",
    "    elif lv_m == 1:\n",
    "        gender_flag.append('M')\n",
    "    else:\n",
    "        gender_flag.append('N') # We get these because twitter looks in more than just the tweet text field for the keyword but\n",
    "                                # we are only interested in those that acutally mention the candidate in the tweet.\n",
    "\n",
    "df['Female_candidate'] = f_flag\n",
    "df['Male_candidate'] = m_flag\n",
    "df['Gender_Mentioned'] = gender_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Gender_Mentioned'].value_counts())\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now filter out those who don't mention a candidate in the actual tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Gender_Mentioned'] != 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/kmentzer/Desktop/poltweet_Step4Done.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Info\n",
    "#### Started with 17,178,617 tweets\n",
    "#### There were 4,582,978 that didn't mention one of the candidates in the tweet text field\n",
    "#### Left with 12,595,639 - this becomes our N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Classify Retweets\n",
    "\n",
    "This will classify whether a tweet is a retweet, and if so, also identify who was retweeted (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_flag = []\n",
    "rt_author = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    #tweet = row['CleanTweet']\n",
    "    tweet = row['Text']\n",
    "    tweet = str(tweet).lower()\n",
    "\n",
    "    if tweet.startswith('rt '):\n",
    "        tweet_author = tweet[tweet.find(\"@\")+1:tweet.find(\":\")]\n",
    "        if tweet_author == '': # If the tweet starts with RT but we can't find the author, we are treating it as a non-RT\n",
    "            rt_flag.append(0)\n",
    "            rt_author.append(tweet_author)\n",
    "        else:    \n",
    "            rt_flag.append(1)\n",
    "            rt_author.append(tweet_author)\n",
    "    else:\n",
    "        rt_flag.append(0)\n",
    "        rt_author.append('')\n",
    "\n",
    "df['Retweet'] = rt_flag\n",
    "df['OrigAuthor'] = rt_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3743110\n",
      "0    2533779\n",
      "Name: Retweet, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Retweet'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Info:\n",
    "#### Retweets: 7,823,472\n",
    "#### Original Tweets: 4,772,167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's create our network\n",
    "\n",
    "Start by creating a dataframe with just the retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrt = df.loc[df['Retweet'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Hashtags              TweetID                       TweetDate  \\\n",
      "6276877       []  1306231564737576969  Wed Sep 16 14:00:48 +0000 2020   \n",
      "6276879       []  1306231564762640386  Wed Sep 16 14:00:48 +0000 2020   \n",
      "6276881       []  1306231564808851457  Wed Sep 16 14:00:48 +0000 2020   \n",
      "6276882       []  1306231564926320640  Wed Sep 16 14:00:48 +0000 2020   \n",
      "6276883       []  1306231564905320449  Wed Sep 16 14:00:48 +0000 2020   \n",
      "\n",
      "                                                                                                                                                           Text  \\\n",
      "6276877      RT @amyklobuchar: In the Scientific American's first endorsement ever, @sciam chose @JoeBiden. \\r\\n\\r\\nThey understand the weight of this electio‚Ä¶   \n",
      "6276879            RT @JamesOKeefeIII: BREAKING: @AmyMcgrathKY staff choose deceit of KY @realDonaldTrump voters by ‚Äúnot like talking about specific policy...‚Ä¶   \n",
      "6276881  RT @PiperPerabo: @DougJones I heard this speech by  @DougJones &amp; decided to do all I could to support him.\\r\\n\\r\\nDoug Jones is a civil rights he‚Ä¶   \n",
      "6276882                                                                      RT @smc429: @ProjectLincoln @realDonaldTrump Green Fakers! https://t.co/fHekYGEYtp   \n",
      "6276883                                       RT @GOPChairwoman: ‚ÄúWe‚Äôre actually creating peace in the Middle East.‚Äù ‚Äì @realDonaldTrump https://t.co/vECMLNOe5P   \n",
      "\n",
      "                                  Name             User              UserID  \\\n",
      "6276877         Maaike van OosteromüçÉüçÇüçÅ       oosterom_m          4397025089   \n",
      "6276879                       Nana_Deb  NanaDeb42271069  966454254704590848   \n",
      "6276881                      Sdnews619        sdnews619            22266756   \n",
      "6276882  Pre-existing Condition. @üè° üåäüåä    gh14hinojosa5  862341828410052609   \n",
      "6276883                        America  AMERICA20215759  949664411886604290   \n",
      "\n",
      "               UserLoc  \\\n",
      "6276877      Nederland   \n",
      "6276879  Union Gap, WA   \n",
      "6276881  San Diego, CA   \n",
      "6276882  United States   \n",
      "6276883       America    \n",
      "\n",
      "                                                                                                                                                             UserDesc  \\\n",
      "6276877                                                                                                                      mother, writer, student\\r\\n#teamherfst‚ù§Ô∏è   \n",
      "6276879                                                                                                                                 Politics Country General News   \n",
      "6276881                                                                                                                                                            SD   \n",
      "6276882  Retired Librarian. Good manners cost nothing.There is no such thing as  magic. Keep your religion to yourself.  #RESIST. üåäüåä #NoWall NO DMs. #wearthedamnmask   \n",
      "6276883                                                                                 American Realist, I SERVE JESUS CHRIST‚úùÔ∏è Thankful üá∫üá∏üá∫üá∏üáÆüá±üá∫üá∏üá∫üá∏ Learn to Laugh üòÇ   \n",
      "\n",
      "         UserFollowers  UserFriends  UserListed  \\\n",
      "6276877            190          112           1   \n",
      "6276879           1245         1392           0   \n",
      "6276881            111         1393           5   \n",
      "6276882           2510         3095          12   \n",
      "6276883            157         1851           0   \n",
      "\n",
      "                            UserCreated  UserFavs  UserVerified  UserStatuses  \\\n",
      "6276877  Sun Dec 06 19:28:40 +0000 2015     58910         False         43455   \n",
      "6276879  Wed Feb 21 23:27:04 +0000 2018     83167         False         93017   \n",
      "6276881  Sat Feb 28 15:50:56 +0000 2009    127440         False         31858   \n",
      "6276882  Wed May 10 16:21:28 +0000 2017     37700         False         36153   \n",
      "6276883  Sat Jan 06 15:30:14 +0000 2018     22345         False         22590   \n",
      "\n",
      "                                                                                                                                              CleanTweet  \\\n",
      "6276877      rt amyklobuchar in the scientific americans first endorsement ever sciam chose joebiden \\r\\n\\r\\nthey understand the weight of this electio‚Ä¶   \n",
      "6276879             rt jamesokeefeiii breaking amymcgrathky staff choose deceit of ky realdonaldtrump voters by ‚Äúnot like talking about specific policy‚Ä¶   \n",
      "6276881  rt piperperabo dougjones i heard this speech by  dougjones amp decided to do all i could to support him\\r\\n\\r\\ndoug jones is a civil rights he‚Ä¶   \n",
      "6276882                                                                         rt smc429 projectlincoln realdonaldtrump green fakers httpstcofhekygeytp   \n",
      "6276883                                         rt gopchairwoman ‚Äúwe‚Äôre actually creating peace in the middle east‚Äù ‚Äì realdonaldtrump httpstcovecmlnoe5p   \n",
      "\n",
      "         Female_candidate  Male_candidate Gender_Mentioned  Retweet  \\\n",
      "6276877                 0               0                N        1   \n",
      "6276879                 1               0                F        1   \n",
      "6276881                 0               0                N        1   \n",
      "6276882                 0               0                N        1   \n",
      "6276883                 0               0                N        1   \n",
      "\n",
      "             OrigAuthor  Polarity  Subjectivity  \n",
      "6276877    amyklobuchar      0.25      0.333333  \n",
      "6276879  jamesokeefeiii      0.00      0.125000  \n",
      "6276881     piperperabo      0.00      0.000000  \n",
      "6276882          smc429     -0.20      0.300000  \n",
      "6276883   gopchairwoman      0.00      0.050000  \n"
     ]
    }
   ],
   "source": [
    "print(dfrt.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get it down to just the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>Text</th>\n",
       "      <th>Name</th>\n",
       "      <th>User</th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserLoc</th>\n",
       "      <th>UserDesc</th>\n",
       "      <th>UserFollowers</th>\n",
       "      <th>UserFriends</th>\n",
       "      <th>UserListed</th>\n",
       "      <th>UserCreated</th>\n",
       "      <th>UserFavs</th>\n",
       "      <th>UserVerified</th>\n",
       "      <th>UserStatuses</th>\n",
       "      <th>CleanTweet</th>\n",
       "      <th>Female_candidate</th>\n",
       "      <th>Male_candidate</th>\n",
       "      <th>Gender_Mentioned</th>\n",
       "      <th>OrigAuthor</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163585806336</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶</td>\n",
       "      <td>ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è</td>\n",
       "      <td>NinerNabs49</td>\n",
       "      <td>1904396719</td>\n",
       "      <td>NorCal</td>\n",
       "      <td>Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020</td>\n",
       "      <td>3410</td>\n",
       "      <td>912</td>\n",
       "      <td>65</td>\n",
       "      <td>Wed Sep 25 14:10:01 +0000 2013</td>\n",
       "      <td>43871</td>\n",
       "      <td>False</td>\n",
       "      <td>41225</td>\n",
       "      <td>rt herschelwalker ‚Å¶joebiden‚Å© came to office 1973 6 term senator 2 term vp  what did he do for african americans remember black and‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>herschelwalker</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163548012546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶</td>\n",
       "      <td>Joni Skibo/LaCroix</td>\n",
       "      <td>Joni_Looking</td>\n",
       "      <td>857936728165896204</td>\n",
       "      <td>Homes in MI &amp; FL</td>\n",
       "      <td>VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 &amp; S2006\\r\\n&amp;Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic &amp; Design Quilts</td>\n",
       "      <td>5382</td>\n",
       "      <td>3863</td>\n",
       "      <td>28</td>\n",
       "      <td>Fri Apr 28 12:37:10 +0000 2017</td>\n",
       "      <td>493141</td>\n",
       "      <td>False</td>\n",
       "      <td>829357</td>\n",
       "      <td>rt cermwgpsue if you can donate to captmarkkelly to help him keep his leadrepubs have sunk millions into trying to save mcsally‚Äôs seat‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>cermwgpsue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163778748417</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶</td>\n",
       "      <td>I Stand 4 Life</td>\n",
       "      <td>Stand4AllLife</td>\n",
       "      <td>859812116227735552</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>#ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com</td>\n",
       "      <td>1838</td>\n",
       "      <td>3413</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 03 16:49:17 +0000 2017</td>\n",
       "      <td>25296</td>\n",
       "      <td>False</td>\n",
       "      <td>25012</td>\n",
       "      <td>rt kassie917 i am so sick of the media dictating the narrative in this country‚Ä§ i‚Äôm so sick of having to be apologetic for who i am i‚Äôm‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>kassie917</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163845996546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶</td>\n",
       "      <td>üíô Tonia üíô</td>\n",
       "      <td>ToniaJohns18</td>\n",
       "      <td>1218658110526689280</td>\n",
       "      <td>MN USA</td>\n",
       "      <td>üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§</td>\n",
       "      <td>8247</td>\n",
       "      <td>8510</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat Jan 18 22:15:47 +0000 2020</td>\n",
       "      <td>35670</td>\n",
       "      <td>False</td>\n",
       "      <td>13340</td>\n",
       "      <td>rt donnellyantonia realdonaldtrump hes only raising taxes on people who make over 400000 dollars  quit your lying  youve crashed‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>donnellyantonia</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995164084842497</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @paulcshipley: @realDonaldTrump From @BryanDawsonUSA \\r\\nJoe Biden went to Sunday mass &amp;amp; visited his son's grave. Trump's campaign ridicule‚Ä¶</td>\n",
       "      <td>Tracy Wise</td>\n",
       "      <td>FrauWise</td>\n",
       "      <td>213159189</td>\n",
       "      <td>California</td>\n",
       "      <td>Focused on the present moment in the US &amp; around the world. Supporter of liberal democracy. Personal account. *opinions my own* RT's=look at this (vs approval)</td>\n",
       "      <td>1385</td>\n",
       "      <td>2996</td>\n",
       "      <td>25</td>\n",
       "      <td>Mon Nov 08 03:50:10 +0000 2010</td>\n",
       "      <td>289050</td>\n",
       "      <td>False</td>\n",
       "      <td>124278</td>\n",
       "      <td>rt paulcshipley realdonaldtrump from bryandawsonusa \\r\\njoe biden went to sunday mass amp visited his sons grave trumps campaign ridicule‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>paulcshipley</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1306231564737576969</td>\n",
       "      <td>Wed Sep 16 14:00:48 +0000 2020</td>\n",
       "      <td>RT @amyklobuchar: In the Scientific American's first endorsement ever, @sciam chose @JoeBiden. \\r\\n\\r\\nThey understand the weight of this electio‚Ä¶</td>\n",
       "      <td>Maaike van OosteromüçÉüçÇüçÅ</td>\n",
       "      <td>oosterom_m</td>\n",
       "      <td>4397025089</td>\n",
       "      <td>Nederland</td>\n",
       "      <td>mother, writer, student\\r\\n#teamherfst‚ù§Ô∏è</td>\n",
       "      <td>190</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 06 19:28:40 +0000 2015</td>\n",
       "      <td>58910</td>\n",
       "      <td>False</td>\n",
       "      <td>43455</td>\n",
       "      <td>rt amyklobuchar in the scientific americans first endorsement ever sciam chose joebiden \\r\\n\\r\\nthey understand the weight of this electio‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>amyklobuchar</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1306231564762640386</td>\n",
       "      <td>Wed Sep 16 14:00:48 +0000 2020</td>\n",
       "      <td>RT @JamesOKeefeIII: BREAKING: @AmyMcgrathKY staff choose deceit of KY @realDonaldTrump voters by ‚Äúnot like talking about specific policy...‚Ä¶</td>\n",
       "      <td>Nana_Deb</td>\n",
       "      <td>NanaDeb42271069</td>\n",
       "      <td>966454254704590848</td>\n",
       "      <td>Union Gap, WA</td>\n",
       "      <td>Politics Country General News</td>\n",
       "      <td>1245</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed Feb 21 23:27:04 +0000 2018</td>\n",
       "      <td>83167</td>\n",
       "      <td>False</td>\n",
       "      <td>93017</td>\n",
       "      <td>rt jamesokeefeiii breaking amymcgrathky staff choose deceit of ky realdonaldtrump voters by ‚Äúnot like talking about specific policy‚Ä¶</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>jamesokeefeiii</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1306231564808851457</td>\n",
       "      <td>Wed Sep 16 14:00:48 +0000 2020</td>\n",
       "      <td>RT @PiperPerabo: @DougJones I heard this speech by  @DougJones &amp;amp; decided to do all I could to support him.\\r\\n\\r\\nDoug Jones is a civil rights he‚Ä¶</td>\n",
       "      <td>Sdnews619</td>\n",
       "      <td>sdnews619</td>\n",
       "      <td>22266756</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>SD</td>\n",
       "      <td>111</td>\n",
       "      <td>1393</td>\n",
       "      <td>5</td>\n",
       "      <td>Sat Feb 28 15:50:56 +0000 2009</td>\n",
       "      <td>127440</td>\n",
       "      <td>False</td>\n",
       "      <td>31858</td>\n",
       "      <td>rt piperperabo dougjones i heard this speech by  dougjones amp decided to do all i could to support him\\r\\n\\r\\ndoug jones is a civil rights he‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>piperperabo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1306231564926320640</td>\n",
       "      <td>Wed Sep 16 14:00:48 +0000 2020</td>\n",
       "      <td>RT @smc429: @ProjectLincoln @realDonaldTrump Green Fakers! https://t.co/fHekYGEYtp</td>\n",
       "      <td>Pre-existing Condition. @üè° üåäüåä</td>\n",
       "      <td>gh14hinojosa5</td>\n",
       "      <td>862341828410052609</td>\n",
       "      <td>United States</td>\n",
       "      <td>Retired Librarian. Good manners cost nothing.There is no such thing as  magic. Keep your religion to yourself.  #RESIST. üåäüåä #NoWall NO DMs. #wearthedamnmask</td>\n",
       "      <td>2510</td>\n",
       "      <td>3095</td>\n",
       "      <td>12</td>\n",
       "      <td>Wed May 10 16:21:28 +0000 2017</td>\n",
       "      <td>37700</td>\n",
       "      <td>False</td>\n",
       "      <td>36153</td>\n",
       "      <td>rt smc429 projectlincoln realdonaldtrump green fakers httpstcofhekygeytp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>smc429</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1306231564905320449</td>\n",
       "      <td>Wed Sep 16 14:00:48 +0000 2020</td>\n",
       "      <td>RT @GOPChairwoman: ‚ÄúWe‚Äôre actually creating peace in the Middle East.‚Äù ‚Äì @realDonaldTrump https://t.co/vECMLNOe5P</td>\n",
       "      <td>America</td>\n",
       "      <td>AMERICA20215759</td>\n",
       "      <td>949664411886604290</td>\n",
       "      <td>America</td>\n",
       "      <td>American Realist, I SERVE JESUS CHRIST‚úùÔ∏è Thankful üá∫üá∏üá∫üá∏üáÆüá±üá∫üá∏üá∫üá∏ Learn to Laugh üòÇ</td>\n",
       "      <td>157</td>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jan 06 15:30:14 +0000 2018</td>\n",
       "      <td>22345</td>\n",
       "      <td>False</td>\n",
       "      <td>22590</td>\n",
       "      <td>rt gopchairwoman ‚Äúwe‚Äôre actually creating peace in the middle east‚Äù ‚Äì realdonaldtrump httpstcovecmlnoe5p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>gopchairwoman</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3743110 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Hashtags              TweetID                       TweetDate  \\\n",
       "Retweet                                                                 \n",
       "1             []  1302995163585806336  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1             []  1302995163548012546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1             []  1302995163778748417  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1             []  1302995163845996546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1             []  1302995164084842497  Mon Sep 07 15:40:30 +0000 2020   \n",
       "...          ...                  ...                             ...   \n",
       "1             []  1306231564737576969  Wed Sep 16 14:00:48 +0000 2020   \n",
       "1             []  1306231564762640386  Wed Sep 16 14:00:48 +0000 2020   \n",
       "1             []  1306231564808851457  Wed Sep 16 14:00:48 +0000 2020   \n",
       "1             []  1306231564926320640  Wed Sep 16 14:00:48 +0000 2020   \n",
       "1             []  1306231564905320449  Wed Sep 16 14:00:48 +0000 2020   \n",
       "\n",
       "                                                                                                                                                           Text  \\\n",
       "Retweet                                                                                                                                                           \n",
       "1                   RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶   \n",
       "1                  RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶   \n",
       "1                  RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶   \n",
       "1                   RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶   \n",
       "1           RT @paulcshipley: @realDonaldTrump From @BryanDawsonUSA \\r\\nJoe Biden went to Sunday mass &amp; visited his son's grave. Trump's campaign ridicule‚Ä¶   \n",
       "...                                                                                                                                                         ...   \n",
       "1            RT @amyklobuchar: In the Scientific American's first endorsement ever, @sciam chose @JoeBiden. \\r\\n\\r\\nThey understand the weight of this electio‚Ä¶   \n",
       "1                  RT @JamesOKeefeIII: BREAKING: @AmyMcgrathKY staff choose deceit of KY @realDonaldTrump voters by ‚Äúnot like talking about specific policy...‚Ä¶   \n",
       "1        RT @PiperPerabo: @DougJones I heard this speech by  @DougJones &amp; decided to do all I could to support him.\\r\\n\\r\\nDoug Jones is a civil rights he‚Ä¶   \n",
       "1                                                                            RT @smc429: @ProjectLincoln @realDonaldTrump Green Fakers! https://t.co/fHekYGEYtp   \n",
       "1                                             RT @GOPChairwoman: ‚ÄúWe‚Äôre actually creating peace in the Middle East.‚Äù ‚Äì @realDonaldTrump https://t.co/vECMLNOe5P   \n",
       "\n",
       "                                  Name             User               UserID  \\\n",
       "Retweet                                                                        \n",
       "1        ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è      NinerNabs49           1904396719   \n",
       "1                   Joni Skibo/LaCroix     Joni_Looking   857936728165896204   \n",
       "1                       I Stand 4 Life    Stand4AllLife   859812116227735552   \n",
       "1                            üíô Tonia üíô     ToniaJohns18  1218658110526689280   \n",
       "1                           Tracy Wise         FrauWise            213159189   \n",
       "...                                ...              ...                  ...   \n",
       "1               Maaike van OosteromüçÉüçÇüçÅ       oosterom_m           4397025089   \n",
       "1                             Nana_Deb  NanaDeb42271069   966454254704590848   \n",
       "1                            Sdnews619        sdnews619             22266756   \n",
       "1        Pre-existing Condition. @üè° üåäüåä    gh14hinojosa5   862341828410052609   \n",
       "1                              America  AMERICA20215759   949664411886604290   \n",
       "\n",
       "                  UserLoc  \\\n",
       "Retweet                     \n",
       "1                  NorCal   \n",
       "1        Homes in MI & FL   \n",
       "1              Irvine, CA   \n",
       "1                  MN USA   \n",
       "1              California   \n",
       "...                   ...   \n",
       "1               Nederland   \n",
       "1           Union Gap, WA   \n",
       "1           San Diego, CA   \n",
       "1           United States   \n",
       "1                America    \n",
       "\n",
       "                                                                                                                                                                                      UserDesc  \\\n",
       "Retweet                                                                                                                                                                                          \n",
       "1                                                         Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020   \n",
       "1        VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 & S2006\\r\\n&Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic & Design Quilts   \n",
       "1                                                  #ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com   \n",
       "1                                 üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§   \n",
       "1                              Focused on the present moment in the US & around the world. Supporter of liberal democracy. Personal account. *opinions my own* RT's=look at this (vs approval)   \n",
       "...                                                                                                                                                                                        ...   \n",
       "1                                                                                                                                                     mother, writer, student\\r\\n#teamherfst‚ù§Ô∏è   \n",
       "1                                                                                                                                                                Politics Country General News   \n",
       "1                                                                                                                                                                                           SD   \n",
       "1                                 Retired Librarian. Good manners cost nothing.There is no such thing as  magic. Keep your religion to yourself.  #RESIST. üåäüåä #NoWall NO DMs. #wearthedamnmask   \n",
       "1                                                                                                                American Realist, I SERVE JESUS CHRIST‚úùÔ∏è Thankful üá∫üá∏üá∫üá∏üáÆüá±üá∫üá∏üá∫üá∏ Learn to Laugh üòÇ   \n",
       "\n",
       "         UserFollowers  UserFriends  UserListed  \\\n",
       "Retweet                                           \n",
       "1                 3410          912          65   \n",
       "1                 5382         3863          28   \n",
       "1                 1838         3413           1   \n",
       "1                 8247         8510           4   \n",
       "1                 1385         2996          25   \n",
       "...                ...          ...         ...   \n",
       "1                  190          112           1   \n",
       "1                 1245         1392           0   \n",
       "1                  111         1393           5   \n",
       "1                 2510         3095          12   \n",
       "1                  157         1851           0   \n",
       "\n",
       "                            UserCreated  UserFavs  UserVerified  UserStatuses  \\\n",
       "Retweet                                                                         \n",
       "1        Wed Sep 25 14:10:01 +0000 2013     43871         False         41225   \n",
       "1        Fri Apr 28 12:37:10 +0000 2017    493141         False        829357   \n",
       "1        Wed May 03 16:49:17 +0000 2017     25296         False         25012   \n",
       "1        Sat Jan 18 22:15:47 +0000 2020     35670         False         13340   \n",
       "1        Mon Nov 08 03:50:10 +0000 2010    289050         False        124278   \n",
       "...                                 ...       ...           ...           ...   \n",
       "1        Sun Dec 06 19:28:40 +0000 2015     58910         False         43455   \n",
       "1        Wed Feb 21 23:27:04 +0000 2018     83167         False         93017   \n",
       "1        Sat Feb 28 15:50:56 +0000 2009    127440         False         31858   \n",
       "1        Wed May 10 16:21:28 +0000 2017     37700         False         36153   \n",
       "1        Sat Jan 06 15:30:14 +0000 2018     22345         False         22590   \n",
       "\n",
       "                                                                                                                                              CleanTweet  \\\n",
       "Retweet                                                                                                                                                    \n",
       "1                    rt herschelwalker ‚Å¶joebiden‚Å© came to office 1973 6 term senator 2 term vp  what did he do for african americans remember black and‚Ä¶   \n",
       "1                rt cermwgpsue if you can donate to captmarkkelly to help him keep his leadrepubs have sunk millions into trying to save mcsally‚Äôs seat‚Ä¶   \n",
       "1               rt kassie917 i am so sick of the media dictating the narrative in this country‚Ä§ i‚Äôm so sick of having to be apologetic for who i am i‚Äôm‚Ä¶   \n",
       "1                      rt donnellyantonia realdonaldtrump hes only raising taxes on people who make over 400000 dollars  quit your lying  youve crashed‚Ä¶   \n",
       "1             rt paulcshipley realdonaldtrump from bryandawsonusa \\r\\njoe biden went to sunday mass amp visited his sons grave trumps campaign ridicule‚Ä¶   \n",
       "...                                                                                                                                                  ...   \n",
       "1            rt amyklobuchar in the scientific americans first endorsement ever sciam chose joebiden \\r\\n\\r\\nthey understand the weight of this electio‚Ä¶   \n",
       "1                   rt jamesokeefeiii breaking amymcgrathky staff choose deceit of ky realdonaldtrump voters by ‚Äúnot like talking about specific policy‚Ä¶   \n",
       "1        rt piperperabo dougjones i heard this speech by  dougjones amp decided to do all i could to support him\\r\\n\\r\\ndoug jones is a civil rights he‚Ä¶   \n",
       "1                                                                               rt smc429 projectlincoln realdonaldtrump green fakers httpstcofhekygeytp   \n",
       "1                                               rt gopchairwoman ‚Äúwe‚Äôre actually creating peace in the middle east‚Äù ‚Äì realdonaldtrump httpstcovecmlnoe5p   \n",
       "\n",
       "         Female_candidate  Male_candidate Gender_Mentioned       OrigAuthor  \\\n",
       "Retweet                                                                       \n",
       "1                       0               0                N   herschelwalker   \n",
       "1                       0               1                M       cermwgpsue   \n",
       "1                       0               0                N        kassie917   \n",
       "1                       0               0                N  donnellyantonia   \n",
       "1                       0               0                N     paulcshipley   \n",
       "...                   ...             ...              ...              ...   \n",
       "1                       0               0                N     amyklobuchar   \n",
       "1                       1               0                F   jamesokeefeiii   \n",
       "1                       0               0                N      piperperabo   \n",
       "1                       0               0                N           smc429   \n",
       "1                       0               0                N    gopchairwoman   \n",
       "\n",
       "         Polarity  Subjectivity  \n",
       "Retweet                          \n",
       "1       -0.083333      0.216667  \n",
       "1        0.000000      0.000000  \n",
       "1       -0.714286      0.857143  \n",
       "1        0.000000      1.000000  \n",
       "1        0.000000      0.000000  \n",
       "...           ...           ...  \n",
       "1        0.250000      0.333333  \n",
       "1        0.000000      0.125000  \n",
       "1        0.000000      0.000000  \n",
       "1       -0.200000      0.300000  \n",
       "1        0.000000      0.050000  \n",
       "\n",
       "[3743110 rows x 23 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrt.set_index('Retweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             OrigAuthor             User\n",
      "6276877    amyklobuchar       oosterom_m\n",
      "6276879  jamesokeefeiii  NanaDeb42271069\n",
      "6276881     piperperabo        sdnews619\n",
      "6276882          smc429    gh14hinojosa5\n",
      "6276883   gopchairwoman  AMERICA20215759\n"
     ]
    }
   ],
   "source": [
    "dfrt = dfrt[['OrigAuthor', 'User']].copy()\n",
    "print(dfrt.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum =  dfrt.groupby(['OrigAuthor', 'User'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              OrigAuthor             User\n",
      "0         herschelwalker      NinerNabs49\n",
      "1             cermwgpsue     Joni_Looking\n",
      "2              kassie917    Stand4AllLife\n",
      "3        donnellyantonia     ToniaJohns18\n",
      "6           paulcshipley         FrauWise\n",
      "...                  ...              ...\n",
      "6276877     amyklobuchar       oosterom_m\n",
      "6276879   jamesokeefeiii  NanaDeb42271069\n",
      "6276881      piperperabo        sdnews619\n",
      "6276882           smc429    gh14hinojosa5\n",
      "6276883    gopchairwoman  AMERICA20215759\n",
      "\n",
      "[3658271 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfrtsum.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum = dfrt.groupby(['OrigAuthor', 'User']).count().reset_index().rename(columns={0:'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum2 = dfrt.groupby(['OrigAuthor','User']).User.agg('count').to_frame('Weight').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OrigAuthor             User  Weight\n",
      "0  00000ar1500000  IraqiChildGhost       1\n",
      "1  00000ar1500000         SossityX       1\n",
      "2      0000condor      DavidHunt75       1\n",
      "3      0000condor      HippyGrumpy       1\n",
      "4     000hhmmm000     LilGirlTrump       1\n",
      "              OrigAuthor             User  Weight\n",
      "3205761         zzzjazzy      d_copeland5       1\n",
      "3205762         zzzjazzy  davidjo28317150       1\n",
      "3205763         zzzjazzy      ebolanteres       1\n",
      "3205764         zzzjazzy       jmp9999jmp       1\n",
      "3205765  zzzzzzz68637331  laphroaigautist       1\n"
     ]
    }
   ],
   "source": [
    "print(dfrtsum2.head())\n",
    "print(dfrtsum2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.205766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.167618e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.174857e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.800000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Weight\n",
       "count  3.205766e+06\n",
       "mean   1.167618e+00\n",
       "std    1.174857e+00\n",
       "min    1.000000e+00\n",
       "25%    1.000000e+00\n",
       "50%    1.000000e+00\n",
       "75%    1.000000e+00\n",
       "max    4.800000e+02"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrtsum2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum.to_csv('D:/Politics2020/retweet_connections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to create the files that Gephi can import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-1596ef8aaa29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Now we push the list into a Dictionary since Dictionaries can't have duplicates it's an easy way to get rid of duplicates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# We're going to store this in a dataframe so we can add more to it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mnodedf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mnodedf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodedf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         ]\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "\n",
    "# First create a list with all names that were both the retweetee and the user\n",
    "for index, row in df.iterrows():\n",
    "    #tweet = row['CleanTweet']\n",
    "    node = row['OrigAuthor']\n",
    "\n",
    "    nodes.append(node)\n",
    "    \n",
    "    node = row['User']\n",
    "    \n",
    "    nodes.append(node)\n",
    "\n",
    "\n",
    "# Now we push the list into a Dictionary since Dictionaries can't have duplicates it's an easy way to get rid of duplicates.\n",
    "# We're going to store this in a dataframe so we can add more to it\n",
    "nodedf = pd.DataFrame(dict.fromkeys(nodes))\n",
    "\n",
    "nodedf = nodedf.reset_index()\n",
    "nodedf.columns[0] = 'Node_ID'\n",
    "nodedf['Node_ID'] = nodedf.index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>Text</th>\n",
       "      <th>Name</th>\n",
       "      <th>User</th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserLoc</th>\n",
       "      <th>UserDesc</th>\n",
       "      <th>UserFollowers</th>\n",
       "      <th>UserFriends</th>\n",
       "      <th>UserListed</th>\n",
       "      <th>UserCreated</th>\n",
       "      <th>UserFavs</th>\n",
       "      <th>UserVerified</th>\n",
       "      <th>UserStatuses</th>\n",
       "      <th>CleanTweet</th>\n",
       "      <th>Female_candidate</th>\n",
       "      <th>Male_candidate</th>\n",
       "      <th>Gender_Mentioned</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>OrigAuthor</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163585806336</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶</td>\n",
       "      <td>ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è</td>\n",
       "      <td>NinerNabs49</td>\n",
       "      <td>1904396719</td>\n",
       "      <td>NorCal</td>\n",
       "      <td>Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020</td>\n",
       "      <td>3410</td>\n",
       "      <td>912</td>\n",
       "      <td>65</td>\n",
       "      <td>Wed Sep 25 14:10:01 +0000 2013</td>\n",
       "      <td>43871</td>\n",
       "      <td>False</td>\n",
       "      <td>41225</td>\n",
       "      <td>rt herschelwalker ‚Å¶joebiden‚Å© came to office 1973 6 term senator 2 term vp  what did he do for african americans remember black and‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>herschelwalker</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163548012546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶</td>\n",
       "      <td>Joni Skibo/LaCroix</td>\n",
       "      <td>Joni_Looking</td>\n",
       "      <td>857936728165896204</td>\n",
       "      <td>Homes in MI &amp; FL</td>\n",
       "      <td>VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 &amp; S2006\\r\\n&amp;Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic &amp; Design Quilts</td>\n",
       "      <td>5382</td>\n",
       "      <td>3863</td>\n",
       "      <td>28</td>\n",
       "      <td>Fri Apr 28 12:37:10 +0000 2017</td>\n",
       "      <td>493141</td>\n",
       "      <td>False</td>\n",
       "      <td>829357</td>\n",
       "      <td>rt cermwgpsue if you can donate to captmarkkelly to help him keep his leadrepubs have sunk millions into trying to save mcsally‚Äôs seat‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>cermwgpsue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163778748417</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶</td>\n",
       "      <td>I Stand 4 Life</td>\n",
       "      <td>Stand4AllLife</td>\n",
       "      <td>859812116227735552</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>#ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com</td>\n",
       "      <td>1838</td>\n",
       "      <td>3413</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 03 16:49:17 +0000 2017</td>\n",
       "      <td>25296</td>\n",
       "      <td>False</td>\n",
       "      <td>25012</td>\n",
       "      <td>rt kassie917 i am so sick of the media dictating the narrative in this country‚Ä§ i‚Äôm so sick of having to be apologetic for who i am i‚Äôm‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>kassie917</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163845996546</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶</td>\n",
       "      <td>üíô Tonia üíô</td>\n",
       "      <td>ToniaJohns18</td>\n",
       "      <td>1218658110526689280</td>\n",
       "      <td>MN USA</td>\n",
       "      <td>üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§</td>\n",
       "      <td>8247</td>\n",
       "      <td>8510</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat Jan 18 22:15:47 +0000 2020</td>\n",
       "      <td>35670</td>\n",
       "      <td>False</td>\n",
       "      <td>13340</td>\n",
       "      <td>rt donnellyantonia realdonaldtrump hes only raising taxes on people who make over 400000 dollars  quit your lying  youve crashed‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>donnellyantonia</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>1302995163787268096</td>\n",
       "      <td>Mon Sep 07 15:40:30 +0000 2020</td>\n",
       "      <td>@JRehling @realDonaldTrump Wait a minute, did he just admit he just CRASHED!!  I don't think I've heard Joe say any‚Ä¶ https://t.co/2HFAvKuxlX</td>\n",
       "      <td>James Huff</td>\n",
       "      <td>JamesHu40978214</td>\n",
       "      <td>1221181060773564418</td>\n",
       "      <td>Leland, NC</td>\n",
       "      <td>I Love the Lord Jesus Christ with all my Heart ‚ô•Ô∏è</td>\n",
       "      <td>362</td>\n",
       "      <td>564</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat Jan 25 21:20:40 +0000 2020</td>\n",
       "      <td>12363</td>\n",
       "      <td>False</td>\n",
       "      <td>10099</td>\n",
       "      <td>jrehling realdonaldtrump wait a minute did he just admit he just crashed  i dont think ive heard joe say any‚Ä¶ httpstco2hfavkuxlx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hashtags              TweetID                       TweetDate  \\\n",
       "0       []  1302995163585806336  Mon Sep 07 15:40:30 +0000 2020   \n",
       "1       []  1302995163548012546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "2       []  1302995163778748417  Mon Sep 07 15:40:30 +0000 2020   \n",
       "3       []  1302995163845996546  Mon Sep 07 15:40:30 +0000 2020   \n",
       "4       []  1302995163787268096  Mon Sep 07 15:40:30 +0000 2020   \n",
       "\n",
       "                                                                                                                                           Text  \\\n",
       "0   RT @HerschelWalker: ‚Å¶@JoeBiden‚Å© came to office 1973! 6 Term Senator, 2 Term VP - what did he do for African Americans? Remember \"Black and‚Ä¶   \n",
       "1  RT @CermwgpSue: If you can, donate to @CaptMarkKelly to help him keep his lead-Repubs have sunk millions into trying to save McSally‚Äôs seat‚Ä¶   \n",
       "2  RT @Kassie917: \"I am so sick of the media dictating the narrative in this country‚Ä§ I‚Äôm so sick of having to be apologetic for who I am. I‚Äôm‚Ä¶   \n",
       "3   RT @DonnellyAntonia: @realDonaldTrump He's only raising taxes on people who make over $400,000. dollars.  Quit your lying.  You've crashed‚Ä¶   \n",
       "4  @JRehling @realDonaldTrump Wait a minute, did he just admit he just CRASHED!!  I don't think I've heard Joe say any‚Ä¶ https://t.co/2HFAvKuxlX   \n",
       "\n",
       "                            Name             User               UserID  \\\n",
       "0  ConservativeCalifornian‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è      NinerNabs49           1904396719   \n",
       "1             Joni Skibo/LaCroix     Joni_Looking   857936728165896204   \n",
       "2                 I Stand 4 Life    Stand4AllLife   859812116227735552   \n",
       "3                      üíô Tonia üíô     ToniaJohns18  1218658110526689280   \n",
       "4                     James Huff  JamesHu40978214  1221181060773564418   \n",
       "\n",
       "            UserLoc  \\\n",
       "0            NorCal   \n",
       "1  Homes in MI & FL   \n",
       "2        Irvine, CA   \n",
       "3            MN USA   \n",
       "4        Leland, NC   \n",
       "\n",
       "                                                                                                                                                                                UserDesc  \\\n",
       "0                                                   Happily married. God Family Friends Patriots üá∫üá∏. @49ers fan. Dems have destroyed California. WIDE AWAKE üòÉ, NOT SLEEPING üò¥ #Trump2020   \n",
       "1  VietNam Vet--Vote4Joe\\r\\n\\r\\nI Fight to BanHorseSlaughter \\r\\n'SAFEAct' HR961 & S2006\\r\\n&Save#NetNeutrality\\r\\n\\r\\n-During DownTime:\\r\\nI Listen to STEVE PerryMusic & Design Quilts   \n",
       "2                                            #ProChild #ProHumanity #ProtectAllLife #ProLife #MAGA #KAG #Trump2020 #SaveTheChildren #LetOurChildrenGo\\r\\n\\r\\nhttps://www.istand4life.com   \n",
       "3                           üò≠Suicide prevention Mental Health advocate üò† I HATE TRUMP VOTE BLUE NOVEMBER 3rd  #StrongerTogether #resister #BidenHarris ‚ù§4 young adult grandkids I ADORE‚ù§   \n",
       "4                                                                                                                                      I Love the Lord Jesus Christ with all my Heart ‚ô•Ô∏è   \n",
       "\n",
       "   UserFollowers  UserFriends  UserListed                     UserCreated  \\\n",
       "0           3410          912          65  Wed Sep 25 14:10:01 +0000 2013   \n",
       "1           5382         3863          28  Fri Apr 28 12:37:10 +0000 2017   \n",
       "2           1838         3413           1  Wed May 03 16:49:17 +0000 2017   \n",
       "3           8247         8510           4  Sat Jan 18 22:15:47 +0000 2020   \n",
       "4            362          564           2  Sat Jan 25 21:20:40 +0000 2020   \n",
       "\n",
       "   UserFavs  UserVerified  UserStatuses  \\\n",
       "0     43871         False         41225   \n",
       "1    493141         False        829357   \n",
       "2     25296         False         25012   \n",
       "3     35670         False         13340   \n",
       "4     12363         False         10099   \n",
       "\n",
       "                                                                                                                                 CleanTweet  \\\n",
       "0       rt herschelwalker ‚Å¶joebiden‚Å© came to office 1973 6 term senator 2 term vp  what did he do for african americans remember black and‚Ä¶   \n",
       "1   rt cermwgpsue if you can donate to captmarkkelly to help him keep his leadrepubs have sunk millions into trying to save mcsally‚Äôs seat‚Ä¶   \n",
       "2  rt kassie917 i am so sick of the media dictating the narrative in this country‚Ä§ i‚Äôm so sick of having to be apologetic for who i am i‚Äôm‚Ä¶   \n",
       "3         rt donnellyantonia realdonaldtrump hes only raising taxes on people who make over 400000 dollars  quit your lying  youve crashed‚Ä¶   \n",
       "4          jrehling realdonaldtrump wait a minute did he just admit he just crashed  i dont think ive heard joe say any‚Ä¶ httpstco2hfavkuxlx   \n",
       "\n",
       "   Female_candidate  Male_candidate Gender_Mentioned  Retweet  \\\n",
       "0                 0               0                N        1   \n",
       "1                 0               1                M        1   \n",
       "2                 0               0                N        1   \n",
       "3                 0               0                N        1   \n",
       "4                 0               0                N        0   \n",
       "\n",
       "        OrigAuthor  Polarity  Subjectivity  \n",
       "0   herschelwalker -0.083333      0.216667  \n",
       "1       cermwgpsue  0.000000      0.000000  \n",
       "2        kassie917 -0.714286      0.857143  \n",
       "3  donnellyantonia  0.000000      1.000000  \n",
       "4                   0.000000      0.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to load the nodes instead of running the block above\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NinerNabs49', 'cermwgpsue', 'Joni_Looking', 'kassie917']\n"
     ]
    }
   ],
   "source": [
    "print(nodes[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = list(dict.fromkeys(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNodes = pd.DataFrame(nodelist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NodeID       NodeLabel\n",
      "0       1  herschelwalker\n",
      "1       2     NinerNabs49\n",
      "2       3      cermwgpsue\n",
      "3       4    Joni_Looking\n",
      "4       5       kassie917\n"
     ]
    }
   ],
   "source": [
    "print(dfNodes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNodes['Node_ID'] = dfNodes.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give ourselves some better labels\n",
    "dfNodes.columns = ['NodeLabel','NodeID']\n",
    "\n",
    "# Gephi requires NodeID first, so let's rearrange the columns\n",
    "dfNodes = dfNodes[['NodeID', 'NodeLabel']] # rearrange column here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a unique list of Nodes along with a Node ID, we'll merge this with our retweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure they are both strings.\n",
    "dfrtsum2.OrigAuthor = dfrtsum2.OrigAuthor.astype(str)\n",
    "dfrtsum2.User = dfrtsum2.User.astype(str)\n",
    "\n",
    "# Now merge using the strings \n",
    "dfEdges = dfrtsum2.merge(dfNodes, left_on='OrigAuthor', right_on='NodeLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OrigAuthor             User  Weight  NodeID       NodeLabel\n",
      "0  00000ar1500000  IraqiChildGhost       1  681143  00000ar1500000\n",
      "1  00000ar1500000         SossityX       1  681143  00000ar1500000\n",
      "2      0000condor      DavidHunt75       1  818597      0000condor\n",
      "3      0000condor      HippyGrumpy       1  818597      0000condor\n",
      "4     000hhmmm000     LilGirlTrump       1  752829     000hhmmm000\n"
     ]
    }
   ],
   "source": [
    "print(dfEdges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra ID\n",
    "dfEdges = dfEdges.drop(['NodeLabel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge using the strings \n",
    "dfEdges = dfEdges.merge(dfNodes, left_on='User', right_on='NodeLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OrigAuthor             User  Weight  NodeID_x  NodeID_y  \\\n",
      "0  00000ar1500000  IraqiChildGhost       1    681143     21467   \n",
      "1          011349  IraqiChildGhost       1    237808     21467   \n",
      "2         11i7am1  IraqiChildGhost       1    206311     21467   \n",
      "3     adrienne711  IraqiChildGhost       1     32909     21467   \n",
      "4       aldecoam1  IraqiChildGhost       1     64480     21467   \n",
      "\n",
      "         NodeLabel  \n",
      "0  IraqiChildGhost  \n",
      "1  IraqiChildGhost  \n",
      "2  IraqiChildGhost  \n",
      "3  IraqiChildGhost  \n",
      "4  IraqiChildGhost  \n"
     ]
    }
   ],
   "source": [
    "print(dfEdges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEdgesOut = dfEdges.filter(['NodeID_x','NodeID_y','Weight'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NodeID_x  NodeID_y  Weight\n",
      "0    681143     21467       1\n",
      "1    237808     21467       1\n",
      "2    206311     21467       1\n",
      "3     32909     21467       1\n",
      "4     64480     21467       1\n"
     ]
    }
   ],
   "source": [
    "print(dfEdgesOut.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our Nodes and Edges\n",
    "# Gephi will require a space as the delimiter. Node labels must be in quotes.\n",
    "\n",
    "#dfEdgesOut.to_csv('D:/Politics2020/test_edges.csv', index=False, delimiter=' ')\n",
    "dfEdgesOut.to_csv('D:/Politics2020/test_edges.csv', index=False, sep=' ')\n",
    "#dfNodes.to_csv('D:/Politics2020/test_nodes.csv', index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import gender_guesser.detector as gender\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "d = gender.Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 10000\n",
      "Count 20000\n",
      "Count 30000\n",
      "Count 40000\n",
      "Count 50000\n",
      "Count 60000\n",
      "Count 70000\n",
      "Count 80000\n",
      "Count 90000\n",
      "Count 100000\n",
      "Count 110000\n",
      "Count 120000\n",
      "Count 130000\n",
      "Count 140000\n",
      "Count 150000\n",
      "Count 160000\n",
      "Count 170000\n",
      "Count 180000\n",
      "Count 190000\n",
      "Count 200000\n",
      "Count 210000\n",
      "Count 220000\n",
      "Count 230000\n",
      "Count 240000\n",
      "Count 250000\n",
      "Count 260000\n",
      "Count 270000\n",
      "Count 280000\n",
      "Count 290000\n",
      "Count 300000\n",
      "Count 310000\n",
      "Count 320000\n",
      "Count 330000\n",
      "Count 340000\n",
      "Count 350000\n",
      "Count 360000\n",
      "Count 370000\n",
      "Count 380000\n",
      "Count 390000\n",
      "Count 400000\n",
      "Count 410000\n",
      "Count 420000\n",
      "Count 430000\n",
      "Count 440000\n",
      "Count 450000\n",
      "Count 460000\n",
      "Count 470000\n",
      "Count 480000\n",
      "Count 490000\n",
      "Count 500000\n",
      "Count 510000\n",
      "Count 520000\n",
      "Count 530000\n",
      "Count 540000\n",
      "Count 550000\n",
      "Count 560000\n",
      "Count 570000\n",
      "Count 580000\n",
      "Count 590000\n",
      "Count 600000\n",
      "Count 610000\n",
      "Count 620000\n",
      "Count 630000\n",
      "Count 640000\n",
      "Count 650000\n",
      "Count 660000\n",
      "Count 670000\n",
      "Count 680000\n",
      "Count 690000\n",
      "Count 700000\n",
      "Count 710000\n",
      "Count 720000\n",
      "Count 730000\n",
      "Count 740000\n",
      "Count 750000\n",
      "Count 760000\n",
      "Count 770000\n",
      "Count 780000\n",
      "Count 790000\n",
      "Count 800000\n",
      "Count 810000\n",
      "Count 820000\n",
      "Count 830000\n",
      "Count 840000\n",
      "Count 850000\n",
      "Count 860000\n",
      "Count 870000\n",
      "Count 880000\n",
      "Count 890000\n",
      "Count 900000\n",
      "Count 910000\n",
      "Count 920000\n",
      "Count 930000\n",
      "Count 940000\n",
      "Count 950000\n",
      "Count 960000\n",
      "Count 970000\n",
      "Count 980000\n",
      "Count 990000\n",
      "Count 1000000\n",
      "Count 1010000\n",
      "Count 1020000\n",
      "Count 1030000\n",
      "Count 1040000\n",
      "Count 1050000\n",
      "Count 1060000\n",
      "Count 1070000\n",
      "Count 1080000\n",
      "Count 1090000\n",
      "Count 1100000\n",
      "Count 1110000\n",
      "Count 1120000\n",
      "Count 1130000\n",
      "Count 1140000\n",
      "Count 1150000\n",
      "Count 1160000\n",
      "Count 1170000\n",
      "Count 1180000\n",
      "Count 1190000\n",
      "Count 1200000\n",
      "Count 1210000\n",
      "Count 1220000\n",
      "Count 1230000\n",
      "Count 1240000\n",
      "Count 1250000\n",
      "Count 1260000\n",
      "Count 1270000\n",
      "Count 1280000\n",
      "Count 1290000\n",
      "Count 1300000\n",
      "Count 1310000\n",
      "Count 1320000\n",
      "Count 1330000\n",
      "Count 1340000\n",
      "Count 1350000\n",
      "Count 1360000\n",
      "Count 1370000\n",
      "Count 1380000\n",
      "Count 1390000\n",
      "Count 1400000\n",
      "Count 1410000\n",
      "Count 1420000\n",
      "Count 1430000\n",
      "Count 1440000\n",
      "Count 1450000\n",
      "Count 1460000\n",
      "Count 1470000\n",
      "Count 1480000\n",
      "Count 1490000\n",
      "Count 1500000\n",
      "Count 1510000\n",
      "Count 1520000\n",
      "Count 1530000\n",
      "Count 1540000\n",
      "Count 1550000\n",
      "Count 1560000\n",
      "Count 1570000\n",
      "Count 1580000\n",
      "Count 1590000\n",
      "Count 1600000\n",
      "Count 1610000\n",
      "Count 1620000\n",
      "Count 1630000\n",
      "Count 1640000\n",
      "Count 1650000\n",
      "Count 1660000\n",
      "Count 1670000\n",
      "Count 1680000\n",
      "Count 1690000\n",
      "Count 1700000\n",
      "Count 1710000\n",
      "Count 1720000\n",
      "Count 1730000\n",
      "Count 1740000\n",
      "Count 1750000\n",
      "Count 1760000\n",
      "Count 1770000\n",
      "Count 1780000\n",
      "Count 1790000\n",
      "Count 1800000\n",
      "Count 1810000\n",
      "Count 1820000\n",
      "Count 1830000\n",
      "Count 1840000\n",
      "Count 1850000\n",
      "Count 1860000\n",
      "Count 1870000\n",
      "Count 1880000\n",
      "Count 1890000\n",
      "Count 1900000\n",
      "Count 1910000\n",
      "Count 1920000\n",
      "Count 1930000\n",
      "Count 1940000\n",
      "Count 1950000\n",
      "Count 1960000\n",
      "Count 1970000\n",
      "Count 1980000\n",
      "Count 1990000\n",
      "Count 2000000\n",
      "Count 2010000\n",
      "Count 2020000\n",
      "Count 2030000\n",
      "Count 2040000\n",
      "Count 2050000\n",
      "Count 2060000\n",
      "Count 2070000\n",
      "Count 2080000\n",
      "Count 2090000\n",
      "Count 2100000\n",
      "Count 2110000\n",
      "Count 2120000\n",
      "Count 2130000\n",
      "Count 2140000\n",
      "Count 2150000\n",
      "Count 2160000\n",
      "Count 2170000\n",
      "Count 2180000\n",
      "Count 2190000\n",
      "Count 2200000\n",
      "Count 2210000\n",
      "Count 2220000\n",
      "Count 2230000\n",
      "Count 2240000\n",
      "Count 2250000\n",
      "Count 2260000\n",
      "Count 2270000\n",
      "Count 2280000\n",
      "Count 2290000\n",
      "Count 2300000\n",
      "Count 2310000\n",
      "Count 2320000\n",
      "Count 2330000\n",
      "Count 2340000\n",
      "Count 2350000\n",
      "Count 2360000\n",
      "Count 2370000\n",
      "Count 2380000\n",
      "Count 2390000\n",
      "Count 2400000\n",
      "Count 2410000\n",
      "Count 2420000\n",
      "Count 2430000\n",
      "Count 2440000\n",
      "Count 2450000\n",
      "Count 2460000\n",
      "Count 2470000\n",
      "Count 2480000\n",
      "Count 2490000\n",
      "Count 2500000\n",
      "Count 2510000\n",
      "Count 2520000\n",
      "Count 2530000\n",
      "Count 2540000\n",
      "Count 2550000\n",
      "Count 2560000\n",
      "Count 2570000\n",
      "Count 2580000\n",
      "Count 2590000\n",
      "Count 2600000\n",
      "Count 2610000\n",
      "Count 2620000\n",
      "Count 2630000\n",
      "Count 2640000\n",
      "Count 2650000\n",
      "Count 2660000\n",
      "Count 2670000\n",
      "Count 2680000\n",
      "Count 2690000\n",
      "Count 2700000\n",
      "Count 2710000\n",
      "Count 2720000\n",
      "Count 2730000\n",
      "Count 2740000\n",
      "Count 2750000\n",
      "Count 2760000\n",
      "Count 2770000\n",
      "Count 2780000\n",
      "Count 2790000\n",
      "Count 2800000\n",
      "Count 2810000\n",
      "Count 2820000\n",
      "Count 2830000\n",
      "Count 2840000\n",
      "Count 2850000\n",
      "Count 2860000\n",
      "Count 2870000\n",
      "Count 2880000\n",
      "Count 2890000\n",
      "Count 2900000\n",
      "Count 2910000\n",
      "Count 2920000\n",
      "Count 2930000\n",
      "Count 2940000\n",
      "Count 2950000\n",
      "Count 2960000\n",
      "Count 2970000\n",
      "Count 2980000\n",
      "Count 2990000\n",
      "Count 3000000\n",
      "Count 3010000\n",
      "Count 3020000\n",
      "Count 3030000\n",
      "Count 3040000\n",
      "Count 3050000\n",
      "Count 3060000\n",
      "Count 3070000\n",
      "Count 3080000\n",
      "Count 3090000\n",
      "Count 3100000\n",
      "Count 3110000\n",
      "Count 3120000\n",
      "Count 3130000\n",
      "Count 3140000\n",
      "Count 3150000\n",
      "Count 3160000\n",
      "Count 3170000\n",
      "Count 3180000\n",
      "Count 3190000\n",
      "Count 3200000\n",
      "Count 3210000\n",
      "Count 3220000\n",
      "Count 3230000\n",
      "Count 3240000\n",
      "Count 3250000\n",
      "Count 3260000\n",
      "Count 3270000\n",
      "Count 3280000\n",
      "Count 3290000\n",
      "Count 3300000\n",
      "Count 3310000\n",
      "Count 3320000\n",
      "Count 3330000\n",
      "Count 3340000\n",
      "Count 3350000\n",
      "Count 3360000\n",
      "Count 3370000\n",
      "Count 3380000\n",
      "Count 3390000\n",
      "Count 3400000\n",
      "Count 3410000\n",
      "Count 3420000\n",
      "Count 3430000\n",
      "Count 3440000\n",
      "Count 3450000\n",
      "Count 3460000\n",
      "Count 3470000\n",
      "Count 3480000\n",
      "Count 3490000\n",
      "Count 3500000\n",
      "Count 3510000\n",
      "Count 3520000\n",
      "Count 3530000\n",
      "Count 3540000\n",
      "Count 3550000\n",
      "Count 3560000\n",
      "Count 3570000\n",
      "Count 3580000\n",
      "Count 3590000\n",
      "Count 3600000\n",
      "Count 3610000\n",
      "Count 3620000\n",
      "Count 3630000\n",
      "Count 3640000\n",
      "Count 3650000\n",
      "Count 3660000\n",
      "Count 3670000\n",
      "Count 3680000\n",
      "Count 3690000\n",
      "Count 3700000\n",
      "Count 3710000\n",
      "Count 3720000\n",
      "Count 3730000\n",
      "Count 3740000\n",
      "Count 3750000\n",
      "Count 3760000\n",
      "Count 3770000\n",
      "Count 3780000\n",
      "Count 3790000\n",
      "Count 3800000\n",
      "Count 3810000\n",
      "Count 3820000\n",
      "Count 3830000\n",
      "Count 3840000\n",
      "Count 3850000\n",
      "Count 3860000\n",
      "Count 3870000\n",
      "Count 3880000\n",
      "Count 3890000\n",
      "Count 3900000\n",
      "Count 3910000\n",
      "Count 3920000\n",
      "Count 3930000\n",
      "Count 3940000\n",
      "Count 3950000\n",
      "Count 3960000\n",
      "Count 3970000\n",
      "Count 3980000\n",
      "Count 3990000\n",
      "Count 4000000\n",
      "Count 4010000\n",
      "Count 4020000\n",
      "Count 4030000\n",
      "Count 4040000\n",
      "Count 4050000\n",
      "Count 4060000\n",
      "Count 4070000\n",
      "Count 4080000\n",
      "Count 4090000\n",
      "Count 4100000\n",
      "Count 4110000\n",
      "Count 4120000\n",
      "Count 4130000\n",
      "Count 4140000\n",
      "Count 4150000\n",
      "Count 4160000\n",
      "Count 4170000\n",
      "Count 4180000\n",
      "Count 4190000\n",
      "Count 4200000\n",
      "Count 4210000\n",
      "Count 4220000\n",
      "Count 4230000\n",
      "Count 4240000\n",
      "Count 4250000\n",
      "Count 4260000\n",
      "Count 4270000\n",
      "Count 4280000\n",
      "Count 4290000\n",
      "Count 4300000\n",
      "Count 4310000\n",
      "Count 4320000\n",
      "Count 4330000\n",
      "Count 4340000\n",
      "Count 4350000\n",
      "Count 4360000\n",
      "Count 4370000\n",
      "Count 4380000\n",
      "Count 4390000\n",
      "Count 4400000\n",
      "Count 4410000\n",
      "Count 4420000\n",
      "Count 4430000\n",
      "Count 4440000\n",
      "Count 4450000\n",
      "Count 4460000\n",
      "Count 4470000\n",
      "Count 4480000\n",
      "Count 4490000\n",
      "Count 4500000\n",
      "Count 4510000\n",
      "Count 4520000\n",
      "Count 4530000\n",
      "Count 4540000\n",
      "Count 4550000\n",
      "Count 4560000\n",
      "Count 4570000\n",
      "Count 4580000\n",
      "Count 4590000\n",
      "Count 4600000\n",
      "Count 4610000\n",
      "Count 4620000\n",
      "Count 4630000\n",
      "Count 4640000\n",
      "Count 4650000\n",
      "Count 4660000\n",
      "Count 4670000\n",
      "Count 4680000\n",
      "Count 4690000\n",
      "Count 4700000\n",
      "Count 4710000\n",
      "Count 4720000\n",
      "Count 4730000\n",
      "Count 4740000\n",
      "Count 4750000\n",
      "Count 4760000\n",
      "Count 4770000\n",
      "Count 4780000\n",
      "Count 4790000\n",
      "Count 4800000\n",
      "Count 4810000\n",
      "Count 4820000\n",
      "Count 4830000\n",
      "Count 4840000\n",
      "Count 4850000\n",
      "Count 4860000\n",
      "Count 4870000\n",
      "Count 4880000\n",
      "Count 4890000\n",
      "Count 4900000\n",
      "Count 4910000\n",
      "Count 4920000\n",
      "Count 4930000\n",
      "Count 4940000\n",
      "Count 4950000\n",
      "Count 4960000\n",
      "Count 4970000\n",
      "Count 4980000\n",
      "Count 4990000\n",
      "Count 5000000\n",
      "Count 5010000\n",
      "Count 5020000\n",
      "Count 5030000\n",
      "Count 5040000\n",
      "Count 5050000\n",
      "Count 5060000\n",
      "Count 5070000\n",
      "Count 5080000\n",
      "Count 5090000\n",
      "Count 5100000\n",
      "Count 5110000\n",
      "Count 5120000\n",
      "Count 5130000\n",
      "Count 5140000\n",
      "Count 5150000\n",
      "Count 5160000\n",
      "Count 5170000\n",
      "Count 5180000\n",
      "Count 5190000\n",
      "Count 5200000\n",
      "Count 5210000\n",
      "Count 5220000\n",
      "Count 5230000\n",
      "Count 5240000\n",
      "Count 5250000\n",
      "Count 5260000\n",
      "Count 5270000\n",
      "Count 5280000\n",
      "Count 5290000\n",
      "Count 5300000\n",
      "Count 5310000\n",
      "Count 5320000\n",
      "Count 5330000\n",
      "Count 5340000\n",
      "Count 5350000\n",
      "Count 5360000\n",
      "Count 5370000\n",
      "Count 5380000\n",
      "Count 5390000\n",
      "Count 5400000\n",
      "Count 5410000\n",
      "Count 5420000\n",
      "Count 5430000\n",
      "Count 5440000\n",
      "Count 5450000\n",
      "Count 5460000\n",
      "Count 5470000\n",
      "Count 5480000\n",
      "Count 5490000\n",
      "Count 5500000\n",
      "Count 5510000\n",
      "Count 5520000\n",
      "Count 5530000\n",
      "Count 5540000\n",
      "Count 5550000\n",
      "Count 5560000\n",
      "Count 5570000\n",
      "Count 5580000\n",
      "Count 5590000\n",
      "Count 5600000\n",
      "Count 5610000\n",
      "Count 5620000\n",
      "Count 5630000\n",
      "Count 5640000\n",
      "Count 5650000\n",
      "Count 5660000\n",
      "Count 5670000\n",
      "Count 5680000\n",
      "Count 5690000\n",
      "Count 5700000\n",
      "Count 5710000\n",
      "Count 5720000\n",
      "Count 5730000\n",
      "Count 5740000\n",
      "Count 5750000\n",
      "Count 5760000\n",
      "Count 5770000\n",
      "Count 5780000\n",
      "Count 5790000\n",
      "Count 5800000\n",
      "Count 5810000\n",
      "Count 5820000\n",
      "Count 5830000\n",
      "Count 5840000\n",
      "Count 5850000\n",
      "Count 5860000\n",
      "Count 5870000\n",
      "Count 5880000\n",
      "Count 5890000\n",
      "Count 5900000\n",
      "Count 5910000\n",
      "Count 5920000\n",
      "Count 5930000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 5940000\n",
      "Count 5950000\n",
      "Count 5960000\n",
      "Count 5970000\n",
      "Count 5980000\n",
      "Count 5990000\n",
      "Count 6000000\n",
      "Count 6010000\n",
      "Count 6020000\n",
      "Count 6030000\n",
      "Count 6040000\n",
      "Count 6050000\n",
      "Count 6060000\n",
      "Count 6070000\n",
      "Count 6080000\n",
      "Count 6090000\n",
      "Count 6100000\n",
      "Count 6110000\n",
      "Count 6120000\n",
      "Count 6130000\n",
      "Count 6140000\n",
      "Count 6150000\n",
      "Count 6160000\n",
      "Count 6170000\n",
      "Count 6180000\n",
      "Count 6190000\n",
      "Count 6200000\n",
      "Count 6210000\n",
      "Count 6220000\n",
      "Count 6230000\n",
      "Count 6240000\n",
      "Count 6250000\n",
      "Count 6260000\n",
      "Count 6270000\n"
     ]
    }
   ],
   "source": [
    "polarityscore = []\n",
    "subjectivityscore = []\n",
    "counter = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    counter = counter + 1\n",
    "    if counter%10000 == 0:\n",
    "        print(\"Count \" + str(counter))\n",
    "        \n",
    "    tweet = row['CleanTweet']\n",
    "    try:\n",
    "        blob = TextBlob(tweet)\n",
    "        polarityscore.append(blob.sentiment.polarity)\n",
    "        subjectivityscore.append(blob.sentiment.subjectivity)\n",
    "    except:\n",
    "        polarityscore.append(0)\n",
    "        subjectivityscore.append(0)\n",
    "        \n",
    "df['Polarity'] = polarityscore\n",
    "df['Subjectivity'] = subjectivityscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Polarity                   \n",
      "                      mean       std    count\n",
      "Gender_Mentioned                             \n",
      "B                 0.069539  0.279205    79273\n",
      "F                 0.036336  0.191322     8987\n",
      "M                 0.022292  0.272267   155223\n",
      "N                 0.052860  0.291472  6033406\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the roginal sentiment to this new sentiment\n",
    "temp2 = df.groupby('Gender_Mentioned').agg({'Polarity': ['mean', 'std', 'count']})\n",
    "print(temp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the columns we don't need\n",
    "df.drop(['Polarity', 'Subjectivity', 'Tweet',], axis=1)\n",
    "\n",
    "# and rename the new columns back to the original names\n",
    "df.rename(index=str, columns={\"PolarityV2\": \"Polarity\", \"SubjectivityV2\": \"Subjectivity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum.sort_values(by=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfrtsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrtsum.to_csv('d:/polnetv3.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfrtsum.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfrtsum.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will import the data from Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'C:/Users/kmentzer/Dropbox/Bryant/Research/Politics2018/GephiOutput.csv'\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "dfGephi = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGephi.Label = dfGephi.Label.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGephi = dfGephi.drop(['Id', 'timeset'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfGephi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Community/Modularity with our tweet data \n",
    "df = df.merge(dfGephi, left_on='User', right_on='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Sentiment by Modularity Class\n",
    "dfModClass = df.groupby('modularity_class').agg({'PolarityV2': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfModClass[347710:347720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Group the Groups So we can see how many groups there are with very low #s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now assign a party based on the community. Top 10 communities are in this file along with their party designation.\n",
    "input_file = 'C:/Users/kmentzer/Dropbox/Bryant/Research/Politics2018/CommunityParty.csv'\n",
    "data = pd.read_csv(input_file, header = None)\n",
    "dfComm = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfComm.columns = ['Community','Party']\n",
    "print(dfComm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweetComm = df.merge(dfComm, left_on='modularity_class', right_on='Community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweetComm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Community'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = dfTweetComm.groupby('Community').agg({'PolarityV2': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = dfTweetComm.groupby('Party').agg({'PolarityV2': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp4 = dfTweetComm.groupby(['Party','Gen']).agg({'PolarityV2': ['mean', 'std', 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp5 = dfTweetComm.groupby(['Party','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp6 = dfTweetComm.groupby(['Party','Gen','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp6.to_csv('C:/Users/kmentzer/Desktop/sum_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Gender'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is wrong with the gender guesser - we have a lot of nulls. Running to see what the issue is...\n",
    "import csv\n",
    "import pandas as pd\n",
    "import gender_guesser.detector as gender\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "d = gender.Detector()\n",
    "\n",
    "genderguess = []\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "\n",
    "    genderguess.append(d.get_gender(row['FirstName']))\n",
    "    \n",
    "dfTweetComm['Gender2'] = genderguess\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Gender2'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_cand = ['kyrstensinema','kdeleon','senfeinstein','chrismurphyct','senatorcarper','senbillnelson','maziehirono','joeforindiana','senangusking','ringelsteinme','senatorcardin','senwarren','stabenow','amyklobuchar','dbaria','clairecmc','senatortester','janeraybould','repjackyrosen','senatormenendez','martinheinrich','sengillibrand','senatorheitkamp','sensherrodbrown','senbobcasey','senwhitehouse','philbredesen','betoorourke','jennywilsonut','timkaine','mariacantwell','sen_joemanchin','senatorbaldwin','traunerforwy']\n",
    "rep_cand = ['repmcsally','mattcoreyct','robarlett','flgovscott','rcurtis808','braun4indiana','senatorbrakey','campbell4md','diehlforsenate', 'johnjamesmi','newbergerjim','senatorwicker','hawleymo','mattformontana','senatorfischer','deanheller','mickrich4senate','chelefarley','repkevincramer','repjimrenacci','reploubarletta','flanders4senate','marshablackburn','tedcruz','mittromney','coreystewartva','susan_hutch','morriseywv','leahvukmir','senjohnbarrasso','dodsonforsenate', 'bobhugin']\n",
    "oth_cand = ['lucy4senate','votevohra','nealjsimon','va_shiva','bedwell_guy','yefeth', 'drbreckenridge','senatejim','trexhagan','barry4ussenate','newdayfornj','hoffman4us2018','kfkimple','voterivera','msabrin','govgaryjohnson','nealdikeman','bowden4senate','mccandlessreed','sensanders','vasenate2018']\n",
    "\n",
    "win_cand = ['amyklobuchar','braun4indiana','ChrisMurphyCT','DianneFeinstein','FLGovScott','HawleyMO',' kyrstensinema','MariaCantwell','MarshaBlackburn', 'MartinHeinrich','maziehirono','MittRomney','RepJackyRosen','RepKevinCramer','Sen_JoeManchin','SenAngusKing','SenatorBaldwin','SenatorCardin','SenatorCarper','SenatorFischer','SenatorMenendez','SenatorTester','SenatorWicker','SenBobCasey','SenGillibrand','SenJohnBarrasso','SenSanders','SenSherrodBrown','SenWarren','SenWhitehouse','stabenow','tedcruz','timkaine']\n",
    "lose_cand = ['BobHugin','BetoORourke','clairecmc','Campbell4MD','dbaria','CheleFarley','CoreyStewartVA','DeanHeller','lucy4senate','JaneRaybould','VoteVohra','flanders4senate','JennyWilsonUT','JoeforIndiana','kdeleon','nealjsimon','va_shiva','JohnJamesMI','LeahVukmir','bedwell_guy','yefeth','MattCoreyCT','PhilBredesen','DRBreckenridge','MattForMontana','MickRich4Senate','RingelsteinME','MorriseyWV','Barry4USSenate','NewDayForNJ','hoffman4US2018','NewbergerJim','kfkimple','voterivera','msabrin','GovGaryJohnson','rcurtis808','RepGeoffDiehl','SenatorHeitkamp','RepJimRenacci','RepLouBarletta','SenBillNelson','RepMcSally','RobArlett','nealdikeman','Bowden4Senate','McCandlessReed','SenateJim','SenatorBrakey','VASenate2018','Susan_Hutch','TraunerforWY','trexhagan']\n",
    "\n",
    "win_cand = [element.lower() for element in win_cand] \n",
    "lose_cand = [element.lower() for element in lose_cand] \n",
    "\n",
    "d_flag = []\n",
    "r_flag = []\n",
    "i_flag = []\n",
    "w_flag = []\n",
    "l_flag = []\n",
    "\n",
    "             \n",
    "#female_candidates = ['eveforussenate','@','@','@','@','@','@','@', '@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@'] # List all the female candidates here\n",
    "#male_candidates = ['adamkokesh','@','@','@senatorshlikas','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@','@']   # List all the male candidate here\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    tweet = row['CleanTweet']\n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in dem_cand):\n",
    "            d_flag.append(1)\n",
    "        else:\n",
    "            d_flag.append(0)\n",
    "    except:\n",
    "        d_flag.append(0)\n",
    "        \n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in rep_cand):\n",
    "            r_flag.append(1)\n",
    "        else:\n",
    "            r_flag.append(0)\n",
    "    except:\n",
    "        r_flag.append(0)\n",
    "\n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in oth_cand):\n",
    "            i_flag.append(1)\n",
    "        else:\n",
    "            i_flag.append(0)\n",
    "    except:\n",
    "        i_flag.append(0)\n",
    "\n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in win_cand):\n",
    "            w_flag.append(1)\n",
    "        else:\n",
    "            w_flag.append(0)\n",
    "    except:\n",
    "        w_flag.append(0)\n",
    "             \n",
    "    try:\n",
    "        if any(candidate in tweet for candidate in lose_cand):\n",
    "            l_flag.append(1)\n",
    "        else:\n",
    "            l_flag.append(0)\n",
    "    except:\n",
    "        l_flag.append(0)\n",
    "\n",
    "\n",
    "dfTweetComm['Dem_candidate'] = d_flag\n",
    "dfTweetComm['Rep_candidate'] = r_flag\n",
    "dfTweetComm['Ind_candidate'] = i_flag\n",
    "dfTweetComm['Winner'] = w_flag\n",
    "dfTweetComm['Loser'] = l_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Rep_candidate'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp7 = dfTweetComm.groupby(['Party','Dem_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp8 = dfTweetComm.groupby(['Party','Rep_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp9 = dfTweetComm.groupby(['Party','Ind_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp10 = dfTweetComm.groupby(['Party','Gen','Dem_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp11 = dfTweetComm.groupby(['Party','Gen','Rep_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp12 = dfTweetComm.groupby(['Party','Gen','Ind_candidate']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp10)\n",
    "print(temp11)\n",
    "print(temp12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp13 = dfTweetComm.groupby(['Party','Gen','Dem_candidate','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp13.to_csv('C:/Users/kmentzer/Desktop/SS_DemCand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp14 = dfTweetComm.groupby(['Party','Gen','Rep_candidate','Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_flag = []\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    lv_gender = row['Gender2']\n",
    "\n",
    "    if lv_gender == 'male' or lv_gender == 'mostly_male':\n",
    "        g_flag.append('Male')\n",
    "    elif lv_gender == 'female' or lv_gender == 'mostly_female':\n",
    "        g_flag.append('Female')\n",
    "    else:\n",
    "        g_flag.append('Unknown')\n",
    "        \n",
    "dfTweetComm['Gen'] = g_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Gender2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['Gen'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp15 = dfTweetComm.groupby(['Gender_Mentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win or Lose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp16 = dfTweetComm.groupby(['Winner']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp17 = dfTweetComm.groupby(['Loser']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp16)\n",
    "print(temp17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_McSally = []\n",
    "f_Sinema = []\n",
    "f_deLeon = []\n",
    "f_Feinstein = []\n",
    "f_Corey = []\n",
    "f_Murphy = []\n",
    "f_Arlett = []\n",
    "f_Carper = []\n",
    "f_Nelson = []\n",
    "f_Scott = []\n",
    "f_Curtis = []\n",
    "f_Hirono = []\n",
    "f_Brenton = []\n",
    "f_Braun = []\n",
    "f_Donnelly = []\n",
    "f_Brakey = []\n",
    "f_King = []\n",
    "f_Ringelstein = []\n",
    "f_Campbell = []\n",
    "f_Cardin = []\n",
    "f_Simon = []\n",
    "f_Vohra = []\n",
    "f_Ayyadurai = []\n",
    "f_Diehl = []\n",
    "f_Warren = []\n",
    "f_James = []\n",
    "f_Stabenow = []\n",
    "f_Klobuchar = []\n",
    "f_Newberger = []\n",
    "f_Baria = []\n",
    "f_Bedwell = []\n",
    "f_Wicker = []\n",
    "f_JCampbell = []\n",
    "f_Hawley = []\n",
    "f_McCaskill = []\n",
    "f_Breckenridge = []\n",
    "f_Rosendale = []\n",
    "f_Tester = []\n",
    "f_Fischer = []\n",
    "f_Raybould = []\n",
    "f_Schultz = []\n",
    "f_Hagan = []\n",
    "f_Heller = []\n",
    "f_Michaels = []\n",
    "f_Rosen = []\n",
    "f_Flanagan = []\n",
    "f_Hoffman = []\n",
    "f_Hugin = []\n",
    "f_Menendez = []\n",
    "f_Kimple = []\n",
    "f_Rivera = []\n",
    "f_Sabrin = []\n",
    "f_Johnson = []\n",
    "f_Heinrich = []\n",
    "f_Rich = []\n",
    "f_Farley = []\n",
    "f_Gillibrand = []\n",
    "f_Cramer = []\n",
    "f_Heitkamp = []\n",
    "f_Brown = []\n",
    "f_Renacci = []\n",
    "f_Barletta = []\n",
    "f_Casey = []\n",
    "f_Flanders = []\n",
    "f_Whitehouse = []\n",
    "f_Blackburn = []\n",
    "f_Bredesen = []\n",
    "f_Cruz = []\n",
    "f_Dikeman = []\n",
    "f_ORourke = []\n",
    "f_Bowden = []\n",
    "f_McCandless = []\n",
    "f_Romney = []\n",
    "f_Wilson = []\n",
    "f_Sanders = []\n",
    "f_Kaine = []\n",
    "f_Stewart = []\n",
    "f_Waters = []\n",
    "f_Cantwell = []\n",
    "f_Hutchinson = []\n",
    "f_Manchin = []\n",
    "f_Morrisey = []\n",
    "f_Baldwin = []\n",
    "f_Vukmir = []\n",
    "f_Barrasso = []\n",
    "f_Dodson = []\n",
    "f_Trauner = []\n",
    "f_Trump = []\n",
    "f_Clinton = []\n",
    "\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    tweet = row['CleanTweet']\n",
    "    if 'repmcsally' in tweet:\n",
    "        f_McSally.append(1)\n",
    "    else:\n",
    "        f_McSally.append(0)\n",
    "\n",
    "    if 'krystensinema' in tweet:\n",
    "        f_Sinema.append(1)\n",
    "    else:\n",
    "        f_Sinema.append(0)\n",
    "\n",
    "    if 'kdeleon' in tweet:\n",
    "        f_deLeon.append(1)\n",
    "    else:\n",
    "        f_deLeon.append(0)\n",
    "\n",
    "    if 'senfeinstein' in tweet:\n",
    "        f_Feinstein.append(1)\n",
    "    else:\n",
    "        f_Feinstein.append(0)\n",
    "\n",
    "    if 'mattcoreyct' in tweet:\n",
    "        f_Corey.append(1)\n",
    "    else:\n",
    "        f_Corey.append(0)\n",
    "\n",
    "    if 'chrismurphyct' in tweet:\n",
    "        f_Murphy.append(1)\n",
    "    else:\n",
    "        f_Murphy.append(0)\n",
    "\n",
    "    if 'robarlett' in tweet:\n",
    "        f_Arlett.append(1)\n",
    "    else:\n",
    "        f_Arlett.append(0)\n",
    "\n",
    "    if 'senatorcarper' in tweet:\n",
    "        f_Carper.append(1)\n",
    "    else:\n",
    "        f_Carper.append(0)\n",
    "\n",
    "    if 'senbillnelson' in tweet:\n",
    "        f_Nelson.append(1)\n",
    "    else:\n",
    "        f_Nelson.append(0)\n",
    "\n",
    "    if 'flgovscott' in tweet:\n",
    "        f_Scott.append(1)\n",
    "    else:\n",
    "        f_Scott.append(0)\n",
    "\n",
    "    if 'rcurtis808' in tweet:\n",
    "        f_Curtis.append(1)\n",
    "    else:\n",
    "        f_Curtis.append(0)\n",
    "\n",
    "    if 'maziehirono' in tweet:\n",
    "        f_Hirono.append(1)\n",
    "    else:\n",
    "        f_Hirono.append(0)\n",
    "\n",
    "    if 'lucy4senate' in tweet:\n",
    "        f_Brenton.append(1)\n",
    "    else:\n",
    "        f_Brenton.append(0)\n",
    "\n",
    "    if 'braun4indiana' in tweet:\n",
    "        f_Braun.append(1)\n",
    "    else:\n",
    "        f_Braun.append(0)\n",
    "\n",
    "    if 'joeforindiana' in tweet:\n",
    "        f_Donnelly.append(1)\n",
    "    else:\n",
    "        f_Donnelly.append(0)\n",
    "\n",
    "    if 'senatorbrakey' in tweet:\n",
    "        f_Brakey.append(1)\n",
    "    else:\n",
    "        f_Brakey.append(0)\n",
    "\n",
    "    if 'senangusking' in tweet:\n",
    "        f_King.append(1)\n",
    "    else:\n",
    "        f_King.append(0)\n",
    "\n",
    "    if 'ringelsteinme' in tweet:\n",
    "        f_Ringelstein.append(1)\n",
    "    else:\n",
    "        f_Ringelstein.append(0)\n",
    "\n",
    "    if 'campbell4md' in tweet:\n",
    "        f_Campbell.append(1)\n",
    "    else:\n",
    "        f_Campbell.append(0)\n",
    "\n",
    "    if 'senatorcardin' in tweet:\n",
    "        f_Cardin.append(1)\n",
    "    else:\n",
    "        f_Cardin.append(0)\n",
    "\n",
    "    if 'nealjsimon' in tweet:\n",
    "        f_Simon.append(1)\n",
    "    else:\n",
    "        f_Simon.append(0)\n",
    "\n",
    "    if 'votevohra' in tweet:\n",
    "        f_Vohra.append(1)\n",
    "    else:\n",
    "        f_Vohra.append(0)\n",
    "\n",
    "    if 'va_shiva' in tweet:\n",
    "        f_Ayyadurai.append(1)\n",
    "    else:\n",
    "        f_Ayyadurai.append(0)\n",
    "\n",
    "    if 'diehlforsenate' in tweet:\n",
    "        f_Diehl.append(1)\n",
    "    else:\n",
    "        f_Diehl.append(0)\n",
    "\n",
    "    if 'senwarren' in tweet:\n",
    "        f_Warren.append(1)\n",
    "    else:\n",
    "        f_Warren.append(0)\n",
    "\n",
    "    if 'johnjamesmi' in tweet:\n",
    "        f_James.append(1)\n",
    "    else:\n",
    "        f_James.append(0)\n",
    "\n",
    "    if 'stabenow' in tweet:\n",
    "        f_Stabenow.append(1)\n",
    "    else:\n",
    "        f_Stabenow.append(0)\n",
    "\n",
    "    if 'amyklobuchar' in tweet:\n",
    "        f_Klobuchar.append(1)\n",
    "    else:\n",
    "        f_Klobuchar.append(0)\n",
    "\n",
    "    if 'newbergerjim' in tweet:\n",
    "        f_Newberger.append(1)\n",
    "    else:\n",
    "        f_Newberger.append(0)\n",
    "\n",
    "    if 'dbaria' in tweet:\n",
    "        f_Baria.append(1)\n",
    "    else:\n",
    "        f_Baria.append(0)\n",
    "\n",
    "    if 'bedwell_guy' in tweet:\n",
    "        f_Bedwell.append(1)\n",
    "    else:\n",
    "        f_Bedwell.append(0)\n",
    "\n",
    "    if 'senatorwicker' in tweet:\n",
    "        f_Wicker.append(1)\n",
    "    else:\n",
    "        f_Wicker.append(0)\n",
    "\n",
    "    if 'yefeth' in tweet:\n",
    "        f_JCampbell.append(1)\n",
    "    else:\n",
    "        f_JCampbell.append(0)\n",
    "\n",
    "    if 'hawleymo' in tweet:\n",
    "        f_Hawley.append(1)\n",
    "    else:\n",
    "        f_Hawley.append(0)\n",
    "\n",
    "    if 'clairecmc' in tweet:\n",
    "        f_McCaskill.append(1)\n",
    "    else:\n",
    "        f_McCaskill.append(0)\n",
    "\n",
    "    if 'drbreckenridge' in tweet:\n",
    "        f_Breckenridge.append(1)\n",
    "    else:\n",
    "        f_Breckenridge.append(0)\n",
    "\n",
    "    if 'mattformontana' in tweet:\n",
    "        f_Rosendale.append(1)\n",
    "    else:\n",
    "        f_Rosendale.append(0)\n",
    "\n",
    "    if 'senatortester' in tweet:\n",
    "        f_Tester.append(1)\n",
    "    else:\n",
    "        f_Tester.append(0)\n",
    "\n",
    "    if 'senatorfischer' in tweet:\n",
    "        f_Fischer.append(1)\n",
    "    else:\n",
    "        f_Fischer.append(0)\n",
    "\n",
    "    if 'janeraybould' in tweet:\n",
    "        f_Raybould.append(1)\n",
    "    else:\n",
    "        f_Raybould.append(0)\n",
    "\n",
    "    if 'senatejim' in tweet:\n",
    "        f_Schultz.append(1)\n",
    "    else:\n",
    "        f_Schultz.append(0)\n",
    "\n",
    "    if 'trexhagan' in tweet:\n",
    "        f_Hagan.append(1)\n",
    "    else:\n",
    "        f_Hagan.append(0)\n",
    "\n",
    "    if 'deanheller' in tweet:\n",
    "        f_Heller.append(1)\n",
    "    else:\n",
    "        f_Heller.append(0)\n",
    "        \n",
    "    if 'barry4ussenate' in tweet:\n",
    "        f_Michaels.append(1)\n",
    "    else:\n",
    "        f_Michaels.append(0)\n",
    "        \n",
    "    if 'repjackyrosen' in tweet:\n",
    "        f_Rosen.append(1)\n",
    "    else:\n",
    "        f_Rosen.append(0)\n",
    "\n",
    "    if 'newdayfornj' in tweet:\n",
    "        f_Flanagan.append(1)\n",
    "    else:\n",
    "        f_Flanagan.append(0)\n",
    "\n",
    "    if 'hoffman4us2018' in tweet:\n",
    "        f_Hoffman.append(1)\n",
    "    else:\n",
    "        f_Hoffman.append(0)\n",
    "\n",
    "    if 'bobhugin' in tweet:\n",
    "        f_Hugin.append(1)\n",
    "    else:\n",
    "        f_Hugin.append(0)\n",
    "\n",
    "    if 'senatormenendez' in tweet:\n",
    "        f_Menendez.append(1)\n",
    "    else:\n",
    "        f_Menendez.append(0)\n",
    "\n",
    "    if 'kfkimple' in tweet:\n",
    "        f_Kimple.append(1)\n",
    "    else:\n",
    "        f_Kimple.append(0)\n",
    "        \n",
    "    if 'voterivera' in tweet:\n",
    "        f_Rivera.append(1)\n",
    "    else:\n",
    "        f_Rivera.append(0)\n",
    "\n",
    "    if 'msabrin' in tweet:\n",
    "        f_Sabrin.append(1)\n",
    "    else:\n",
    "        f_Sabrin.append(0)\n",
    "\n",
    "    if 'govgaryjohnson' in tweet:\n",
    "        f_Johnson.append(1)\n",
    "    else:\n",
    "        f_Johnson.append(0)\n",
    "\n",
    "    if 'martinheinrich' in tweet:\n",
    "        f_Heinrich.append(1)\n",
    "    else:\n",
    "        f_Heinrich.append(0)\n",
    "\n",
    "    if 'mickrich4senate' in tweet:\n",
    "        f_Rich.append(1)\n",
    "    else:\n",
    "        f_Rich.append(0)\n",
    "\n",
    "    if 'chelefarley' in tweet:\n",
    "        f_Farley.append(1)\n",
    "    else:\n",
    "        f_Farley.append(0)\n",
    "\n",
    "    if 'sengillibrand' in tweet:\n",
    "        f_Gillibrand.append(1)\n",
    "    else:\n",
    "        f_Gillibrand.append(0)\n",
    "\n",
    "    if 'repkevincramer' in tweet:\n",
    "        f_Cramer.append(1)\n",
    "    else:\n",
    "        f_Cramer.append(0)\n",
    "\n",
    "    if 'senatorheitkamp' in tweet:\n",
    "        f_Heitkamp.append(1)\n",
    "    else:\n",
    "        f_Heitkamp.append(0)\n",
    "\n",
    "    if 'sensherrodbrown' in tweet:\n",
    "        f_Brown.append(1)\n",
    "    else:\n",
    "        f_Brown.append(0)\n",
    "\n",
    "    if 'repjimrenacci' in tweet:\n",
    "        f_Renacci.append(1)\n",
    "    else:\n",
    "        f_Renacci.append(0)\n",
    "\n",
    "    if 'reploubarletta' in tweet:\n",
    "        f_Barletta.append(1)\n",
    "    else:\n",
    "        f_Barletta.append(0)\n",
    "\n",
    "    if 'senbobcasey' in tweet:\n",
    "        f_Casey.append(1)\n",
    "    else:\n",
    "        f_Casey.append(0)\n",
    "\n",
    "    if 'flanders4senate' in tweet:\n",
    "        f_Flanders.append(1)\n",
    "    else:\n",
    "        f_Flanders.append(0)\n",
    "\n",
    "    if 'senwhitehouse' in tweet:\n",
    "        f_Whitehouse.append(1)\n",
    "    else:\n",
    "        f_Whitehouse.append(0)\n",
    "\n",
    "    if 'marshablackburn' in tweet:\n",
    "        f_Blackburn.append(1)\n",
    "    else:\n",
    "        f_Blackburn.append(0)\n",
    "\n",
    "    if 'philbredesen' in tweet:\n",
    "        f_Bredesen.append(1)\n",
    "    else:\n",
    "        f_Bredesen.append(0)\n",
    "        \n",
    "    if 'tedcruz' in tweet:\n",
    "        f_Cruz.append(1)\n",
    "    else:\n",
    "        f_Cruz.append(0)\n",
    "\n",
    "    if 'nealdikeman' in tweet:\n",
    "        f_Dikeman.append(1)\n",
    "    else:\n",
    "        f_Dikeman.append(0)\n",
    "\n",
    "    if 'betoorourke' in tweet:\n",
    "        f_ORourke.append(1)\n",
    "    else:\n",
    "        f_ORourke.append(0)\n",
    "\n",
    "    if 'bowden4senate' in tweet:\n",
    "        f_Bowden.append(1)\n",
    "    else:\n",
    "        f_Bowden.append(0)\n",
    "        \n",
    "    if 'mccandlessreed' in tweet:\n",
    "        f_McCandless.append(1)\n",
    "    else:\n",
    "        f_McCandless.append(0)\n",
    "        \n",
    "    if 'mittromney' in tweet:\n",
    "        f_Romney.append(1)\n",
    "    else:\n",
    "        f_Romney.append(0)\n",
    "\n",
    "    if 'jennywilsonut' in tweet:\n",
    "        f_Wilson.append(1)\n",
    "    else:\n",
    "        f_Wilson.append(0)\n",
    "\n",
    "    if 'sensanders' in tweet:\n",
    "        f_Sanders.append(1)\n",
    "    else:\n",
    "        f_Sanders.append(0)\n",
    "\n",
    "    if 'timkaine' in tweet:\n",
    "        f_Kaine.append(1)\n",
    "    else:\n",
    "        f_Kaine.append(0)\n",
    "\n",
    "    if 'coreystewartva' in tweet:\n",
    "        f_Stewart.append(1)\n",
    "    else:\n",
    "        f_Stewart.append(0)\n",
    "\n",
    "    if 'vasenate2018' in tweet:\n",
    "        f_Waters.append(1)\n",
    "    else:\n",
    "        f_Waters.append(0)\n",
    "        \n",
    "    if 'mariacantwell' in tweet:\n",
    "        f_Cantwell.append(1)\n",
    "    else:\n",
    "        f_Cantwell.append(0)\n",
    "\n",
    "    if 'susan_hutch' in tweet:\n",
    "        f_Hutchinson.append(1)\n",
    "    else:\n",
    "        f_Hutchinson.append(0)\n",
    "\n",
    "    if 'sen_joemanchin' in tweet:\n",
    "        f_Manchin.append(1)\n",
    "    else:\n",
    "        f_Manchin.append(0)\n",
    "\n",
    "    if 'morriseywv' in tweet:\n",
    "        f_Morrisey.append(1)\n",
    "    else:\n",
    "        f_Morrisey.append(0)\n",
    "\n",
    "    if 'senatorbaldwin' in tweet:\n",
    "        f_Baldwin.append(1)\n",
    "    else:\n",
    "        f_Baldwin.append(0)\n",
    "\n",
    "    if 'leahvukmir' in tweet:\n",
    "        f_Vukmir.append(1)\n",
    "    else:\n",
    "        f_Vukmir.append(0)\n",
    "\n",
    "    if 'senjohnbarrasso' in tweet:\n",
    "        f_Barrasso.append(1)\n",
    "    else:\n",
    "        f_Barrasso.append(0)\n",
    "\n",
    "    if 'dodsonforsenate' in tweet:\n",
    "        f_Dodson.append(1)\n",
    "    else:\n",
    "        f_Dodson.append(0)\n",
    "\n",
    "    if 'traunerforwy' in tweet:\n",
    "        f_Trauner.append(1)\n",
    "    else:\n",
    "        f_Trauner.append(0)\n",
    "\n",
    "    if 'realdonaldtrump' in tweet:\n",
    "        f_Trump.append(1)\n",
    "    else:\n",
    "        f_Trump.append(0)\n",
    "\n",
    "    if 'hillaryclinton' in tweet:\n",
    "        f_Clinton.append(1)\n",
    "    else:\n",
    "        f_Clinton.append(0)\n",
    "\n",
    "        \n",
    "        \n",
    "dfTweetComm['McSally'] = f_McSally\n",
    "dfTweetComm['Sinema'] = f_Sinema\n",
    "dfTweetComm['deLeon'] = f_deLeon\n",
    "dfTweetComm['Feinstein'] = f_Feinstein\n",
    "dfTweetComm['Corey'] = f_Corey\n",
    "dfTweetComm['Murphy'] = f_Murphy \n",
    "dfTweetComm['Arlett'] = f_Arlett \n",
    "dfTweetComm['Carper'] = f_Carper \n",
    "dfTweetComm['Nelson'] = f_Nelson \n",
    "dfTweetComm['Scott'] = f_Scott \n",
    "dfTweetComm['Curtis'] = f_Curtis \n",
    "dfTweetComm['Hirono'] = f_Hirono \n",
    "dfTweetComm['Brenton'] = f_Brenton\n",
    "dfTweetComm['Braun'] = f_Braun\n",
    "dfTweetComm['Donnelly'] = f_Donnelly\n",
    "dfTweetComm['Brakey'] = f_Brakey\n",
    "dfTweetComm['King'] = f_King\n",
    "dfTweetComm['Ringelstein'] = f_Ringelstein \n",
    "dfTweetComm['Campbell'] = f_Campbell \n",
    "dfTweetComm['Cardin'] = f_Cardin \n",
    "dfTweetComm['Simon'] = f_Simon \n",
    "dfTweetComm['Vohra'] = f_Vohra \n",
    "dfTweetComm['Ayyadurai'] = f_Ayyadurai \n",
    "dfTweetComm['Diehl'] = f_Diehl \n",
    "dfTweetComm['Warren'] = f_Warren \n",
    "dfTweetComm['James'] = f_James \n",
    "dfTweetComm['Stabenow'] = f_Stabenow \n",
    "dfTweetComm['Klobuchar'] = f_Klobuchar \n",
    "dfTweetComm['Newberger'] = f_Newberger \n",
    "dfTweetComm['Baria'] = f_Baria \n",
    "dfTweetComm['Bedwell'] = f_Bedwell \n",
    "dfTweetComm['Wicker'] = f_Wicker \n",
    "dfTweetComm['JCampbell'] = f_JCampbell \n",
    "dfTweetComm['Hawley'] = f_Hawley \n",
    "dfTweetComm['McCaskill'] = f_McCaskill \n",
    "dfTweetComm['Breckenridge'] = f_Breckenridge \n",
    "dfTweetComm['Rosendale'] = f_Rosendale \n",
    "dfTweetComm['Tester'] = f_Tester \n",
    "dfTweetComm['Fischer'] = f_Fischer \n",
    "dfTweetComm['Raybould'] = f_Raybould\n",
    "dfTweetComm['Schultz'] = f_Schultz\n",
    "dfTweetComm['Hagan'] = f_Hagan\n",
    "dfTweetComm['Heller'] = f_Heller\n",
    "dfTweetComm['Michaels'] = f_Michaels\n",
    "dfTweetComm['Rosen'] = f_Rosen\n",
    "dfTweetComm['Flanagan'] = f_Flanagan\n",
    "dfTweetComm['Hoffman'] = f_Hoffman\n",
    "dfTweetComm['Hugin'] = f_Hugin\n",
    "dfTweetComm['Menendez'] = f_Menendez\n",
    "dfTweetComm['Kimple'] = f_Kimple\n",
    "dfTweetComm['Rivera'] = f_Rivera\n",
    "dfTweetComm['Sabrin'] = f_Sabrin\n",
    "dfTweetComm['Johnson'] = f_Johnson\n",
    "dfTweetComm['Heinrich'] = f_Heinrich\n",
    "dfTweetComm['Rich'] = f_Rich\n",
    "dfTweetComm['Farley'] = f_Farley\n",
    "dfTweetComm['Gillibrand'] = f_Gillibrand\n",
    "dfTweetComm['Cramer'] = f_Cramer\n",
    "dfTweetComm['Heitkamp'] = f_Heitkamp\n",
    "dfTweetComm['Brown'] = f_Brown\n",
    "dfTweetComm['Renacci'] = f_Renacci\n",
    "dfTweetComm['Barletta'] = f_Barletta\n",
    "dfTweetComm['Casey'] = f_Casey\n",
    "dfTweetComm['Flanders'] = f_Flanders\n",
    "dfTweetComm['Whitehouse'] = f_Whitehouse\n",
    "dfTweetComm['Blackburn'] = f_Blackburn\n",
    "dfTweetComm['Bredesen'] = f_Bredesen\n",
    "dfTweetComm['Cruz'] = f_Cruz\n",
    "dfTweetComm['Dikeman'] = f_Dikeman\n",
    "dfTweetComm['ORourke'] = f_ORourke\n",
    "dfTweetComm['Bowden'] = f_Bowden\n",
    "dfTweetComm['McCandless'] = f_McCandless\n",
    "dfTweetComm['Romney'] = f_Romney\n",
    "dfTweetComm['Wilson'] = f_Wilson\n",
    "dfTweetComm['Sanders'] = f_Sanders\n",
    "dfTweetComm['Kaine'] = f_Kaine\n",
    "dfTweetComm['Stewart'] = f_Stewart\n",
    "dfTweetComm['Waters'] = f_Waters\n",
    "dfTweetComm['Cantwell'] = f_Cantwell\n",
    "dfTweetComm['Hutchinson'] = f_Hutchinson\n",
    "dfTweetComm['Manchin'] = f_Manchin\n",
    "dfTweetComm['Morrisey'] = f_Morrisey\n",
    "dfTweetComm['Baldwin'] = f_Baldwin\n",
    "dfTweetComm['Vukmir'] = f_Vukmir\n",
    "dfTweetComm['Barrasso'] = f_Barrasso\n",
    "dfTweetComm['Dodson'] = f_Dodson\n",
    "dfTweetComm['Trauner'] = f_Trauner\n",
    "dfTweetComm['Trump'] = f_Trump\n",
    "dfTweetComm['Clinton'] = f_Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['McSally'].value_counts())\n",
    "print(dfTweetComm['Sinema'].value_counts())\n",
    "print(dfTweetComm['deLeon'].value_counts())\n",
    "print(dfTweetComm['Feinstein'].value_counts())\n",
    "print(dfTweetComm['Corey'].value_counts())\n",
    "print(dfTweetComm['Murphy'].value_counts())\n",
    "print(dfTweetComm['Arlett'].value_counts())\n",
    "print(dfTweetComm['Carper'].value_counts())\n",
    "print(dfTweetComm['Nelson'].value_counts())\n",
    "print(dfTweetComm['Scott'].value_counts())\n",
    "print(dfTweetComm['Curtis'].value_counts())\n",
    "print(dfTweetComm['Hirono'].value_counts())\n",
    "print(dfTweetComm['Brenton'].value_counts())\n",
    "print(dfTweetComm['Bredesen'].value_counts())\n",
    "print(dfTweetComm['Braun'].value_counts())\n",
    "print(dfTweetComm['Donnelly'].value_counts())\n",
    "print(dfTweetComm['Brakey'].value_counts())\n",
    "print(dfTweetComm['King'].value_counts())\n",
    "print(dfTweetComm['Ringelstein'].value_counts())\n",
    "print(dfTweetComm['Campbell'].value_counts())\n",
    "print(dfTweetComm['Cardin'].value_counts())\n",
    "print(dfTweetComm['Simon'].value_counts())\n",
    "print(dfTweetComm['Vohra'].value_counts())\n",
    "print(dfTweetComm['Ayyadurai'].value_counts()) \n",
    "print(dfTweetComm['Diehl'].value_counts())\n",
    "print(dfTweetComm['Warren'].value_counts())\n",
    "print(dfTweetComm['James'].value_counts())\n",
    "print(dfTweetComm['Stabenow'].value_counts()) \n",
    "print(dfTweetComm['Klobuchar'].value_counts())\n",
    "print(dfTweetComm['Newberger'].value_counts())\n",
    "print(dfTweetComm['Baria'].value_counts())\n",
    "print(dfTweetComm['Bedwell'].value_counts())\n",
    "print(dfTweetComm['Wicker'].value_counts())\n",
    "print(dfTweetComm['JCampbell'].value_counts()) \n",
    "print(dfTweetComm['Hawley'].value_counts())\n",
    "print(dfTweetComm['McCaskill'].value_counts()) \n",
    "print(dfTweetComm['Breckenridge'].value_counts()) \n",
    "print(dfTweetComm['Rosendale'].value_counts())\n",
    "print(dfTweetComm['Tester'].value_counts())\n",
    "print(dfTweetComm['Fischer'].value_counts())\n",
    "print(dfTweetComm['Raybould'].value_counts())\n",
    "print(dfTweetComm['Schultz'].value_counts())\n",
    "print(dfTweetComm['Hagan'].value_counts())\n",
    "print(dfTweetComm['Heller'].value_counts())\n",
    "print(dfTweetComm['Michaels'].value_counts())\n",
    "print(dfTweetComm['Rosen'].value_counts())\n",
    "print(dfTweetComm['Flanagan'].value_counts())\n",
    "print(dfTweetComm['Hoffman'].value_counts())\n",
    "print(dfTweetComm['Hugin'].value_counts())\n",
    "print(dfTweetComm['Menendez'].value_counts())\n",
    "print(dfTweetComm['Kimple'].value_counts())\n",
    "print(dfTweetComm['Rivera'].value_counts())\n",
    "print(dfTweetComm['Sabrin'].value_counts())\n",
    "print(dfTweetComm['Johnson'].value_counts())\n",
    "print(dfTweetComm['Heinrich'].value_counts())\n",
    "print(dfTweetComm['Rich'].value_counts())\n",
    "print(dfTweetComm['Farley'].value_counts())\n",
    "print(dfTweetComm['Gillibrand'].value_counts())\n",
    "print(dfTweetComm['Cramer'].value_counts())\n",
    "print(dfTweetComm['Heitkamp'].value_counts())\n",
    "print(dfTweetComm['Brown'].value_counts())\n",
    "print(dfTweetComm['Renacci'].value_counts())\n",
    "print(dfTweetComm['Barletta'].value_counts())\n",
    "print(dfTweetComm['Casey'].value_counts())\n",
    "print(dfTweetComm['Flanders'].value_counts())\n",
    "print(dfTweetComm['Whitehouse'].value_counts())\n",
    "print(dfTweetComm['Blackburn'].value_counts())\n",
    "print(dfTweetComm['Cruz'].value_counts())\n",
    "print(dfTweetComm['Dikeman'].value_counts())\n",
    "print(dfTweetComm['ORourke'].value_counts())\n",
    "print(dfTweetComm['Bowden'].value_counts())\n",
    "print(dfTweetComm['McCandless'].value_counts())\n",
    "print(dfTweetComm['Romney'].value_counts())\n",
    "print(dfTweetComm['Wilson'].value_counts())\n",
    "print(dfTweetComm['Sanders'].value_counts())\n",
    "print(dfTweetComm['Kaine'].value_counts())\n",
    "print(dfTweetComm['Stewart'].value_counts())\n",
    "print(dfTweetComm['Waters'].value_counts())\n",
    "print(dfTweetComm['Cantwell'].value_counts())\n",
    "print(dfTweetComm['Hutchinson'].value_counts())\n",
    "print(dfTweetComm['Manchin'].value_counts())\n",
    "print(dfTweetComm['Morrisey'].value_counts())\n",
    "print(dfTweetComm['Baldwin'].value_counts())\n",
    "print(dfTweetComm['Vukmir'].value_counts())\n",
    "print(dfTweetComm['Barrasso'].value_counts())\n",
    "print(dfTweetComm['Dodson'].value_counts())\n",
    "print(dfTweetComm['Trauner'].value_counts())\n",
    "print(dfTweetComm['Trump'].value_counts())\n",
    "print(dfTweetComm['Clinton'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp20 = dfTweetComm.groupby(['Party','Warren']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "temp21 = dfTweetComm.groupby(['Party','Gen','Warren']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp20)\n",
    "print(temp21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp21 = dfTweetComm.groupby(['Party','Gen','Clinton']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(temp21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_flag = []\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    tweetdate = row['TweetDate']\n",
    "    tweetdate = pd.to_datetime(tweetdate)\n",
    "    #date = pd.Timestamp.strptime(tweetdate, format=format)\n",
    "    election_day = pd.Timestamp(year=2018, month=11, day=6)\n",
    "    lv_date = (tweetdate - election_day).days \n",
    "\n",
    "    d_flag.append(lv_date)\n",
    "\n",
    "dfTweetComm['DaysToElection'] = d_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDays = dfTweetComm.groupby(['Party','Gen','DaysToElection']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(tempDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDays.to_csv('C:/Users/kmentzer/Desktop/Sent_by_Day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's export some of the tweets based on Community so we can cluster in SAS. We'll start with one of the smaller groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsubset = dfTweetComm.loc[dfTweetComm['modularity_class'] == 78003]\n",
    "#dfsubset = dfTweetComm.loc[dfTweetComm['modularity_class'] == 347715]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfsubset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfsubset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetOnly = dfsubset[['CleanTweet','PolarityV2']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TweetOnly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetOnly.to_csv('C:/Users/kmentzer/Desktop/T342642.csv', index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetOnly.sort_values(by=['PolarityV2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetOnlySub = dfsubset[['CleanTweet','SubjectivityV2']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetOnlySub.sort_values(by=['SubjectivityV2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_flag = []\n",
    "lv_dem = 0 \n",
    "lv_rep = 0 \n",
    "lv_ind = 0\n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    lv_dem = row['Dem_candidate']\n",
    "    lv_rep = row['Rep_candidate']\n",
    "    lv_ind = row['Ind_candidate']\n",
    "    \n",
    "    if lv_dem == 1 and lv_rep == 0 and lv_ind == 0: # Democrats only\n",
    "        p_flag.append('D')\n",
    "    elif lv_dem == 0 and lv_rep == 1 and lv_ind == 0: # Republicans only\n",
    "        p_flag.append('R')\n",
    "    elif lv_dem == 0 and lv_rep == 0 and lv_ind == 1: # Independents only\n",
    "        p_flag.append('I')\n",
    "    elif lv_dem == 0 and lv_rep == 0 and lv_ind == 0: # No Party mentioned (shouldn't happen)\n",
    "        p_flag.append('N')\n",
    "    else: # Multiple Parties mentioned\n",
    "        p_flag.append('M')\n",
    "        \n",
    "    \n",
    "dfTweetComm['PartyMentioned'] = p_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['PolarityCluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempParty = dfTweetComm.groupby(['Party','PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(tempParty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempParty2 = dfTweetComm.groupby(['Party','Gen','PartyMentioned']).agg({'PolarityV2': ['mean', 'std', 'count']})\n",
    "print(tempParty2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_flag = []\n",
    "lv_pol = 0 \n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    lv_pol = row['PolarityV2']\n",
    "    \n",
    "    if lv_pol >= .5:\n",
    "        p_flag.append(5)\n",
    "    elif lv_pol > 0:  \n",
    "        p_flag.append(4)\n",
    "    elif lv_pol == 0: \n",
    "        p_flag.append(3)\n",
    "    elif lv_pol > -.5:\n",
    "        p_flag.append(2)\n",
    "    elif lv_pol >= -1:\n",
    "        p_flag.append(1)\n",
    "    else:    \n",
    "        p_flag.append(0)        \n",
    "    \n",
    "dfTweetComm['PolarityCluster'] = p_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempParty3 = dfTweetComm.groupby(['Party','Gen','PartyMentioned','PolarityCluster']).agg({'PolarityV2':['count']})\n",
    "print(tempParty3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    print(tempParty3.head(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cluster = []\n",
    "lv_cluster = '' \n",
    "\n",
    "for index, row in dfTweetComm.iterrows():\n",
    "    lv_dem = row['Dem_candidate']\n",
    "    lv_rep = row['Rep_candidate']\n",
    "    lv_ind = row['Ind_candidate']\n",
    "    \n",
    "    if row['Gen'] == 'Female':\n",
    "        if row['Party'] == 'D':\n",
    "            if row['PartyMentioned'] == 'D':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'A'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'B'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'R':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'E'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'F'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'M':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'I'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'J'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            else:\n",
    "                lv_cluster = '0'\n",
    "        elif row['Party'] == 'R':\n",
    "            if row['PartyMentioned'] == 'D':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'M'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'N'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'R':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'Q'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'R'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'M':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'U'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'V'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            else:\n",
    "                lv_cluster = '0'\n",
    "        else:\n",
    "            lv_cluster = '0'\n",
    "    elif row['Gen'] == 'Male':\n",
    "        if row['Party'] == 'D':\n",
    "            if row['PartyMentioned'] == 'D':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'C'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'D'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'R':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'G'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'H'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'M':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'K'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'L'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            else:\n",
    "                lv_cluster = '0'\n",
    "        elif row['Party'] == 'R':\n",
    "            if row['PartyMentioned'] == 'D':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'O'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'P'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'R':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'S'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'T'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            elif row['PartyMentioned'] == 'M':\n",
    "                if row['PolarityCluster'] == 5:\n",
    "                    lv_cluster = 'W'\n",
    "                elif row['PolarityCluster'] == 1:\n",
    "                    lv_cluster = 'X'\n",
    "                else:\n",
    "                    lv_cluster = '0'\n",
    "            else:\n",
    "                lv_cluster = '0'\n",
    "        else:\n",
    "            lv_cluster = '0'\n",
    "    else:\n",
    "        lv_cluster = '0'\n",
    "\n",
    "    p_cluster.append(lv_cluster)     \n",
    "                    \n",
    "dfTweetComm['FinalCluster'] = p_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsubset = dfTweetComm.loc[dfTweetComm['FinalCluster'] == 'X']\n",
    "TweetOnly = dfsubset[['CleanTweet']].copy()\n",
    "TweetOnly.to_csv('C:/Users/kmentzer/Desktop/FC_X.csv', index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['FinalCluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTweetComm['PartyMentioned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_flag = []\n",
    "lv_pol = ''\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    lv_pol = row['PolarityV2']\n",
    "    \n",
    "    if lv_pol > 0:\n",
    "        p_flag.append('P')\n",
    "    elif lv_pol == 0:  \n",
    "        p_flag.append('U')\n",
    "    elif lv_pol < 0: \n",
    "        p_flag.append('N')\n",
    "    else:    \n",
    "        p_flag.append('X')        \n",
    "    \n",
    "df['PolarityCluster'] = p_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['PolarityCluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRetweet = dfTweetComm.groupby(['Party','Retweet']).agg({'PolarityV2':['count']})\n",
    "print(tempRetweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRetweet = dfTweetComm.groupby(['Party','Retweet']).agg({'SubjectivityV2':['mean', 'std', 'count']})\n",
    "print(tempRetweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRetweet = dfTweetComm.groupby(['Party','Retweet']).agg({'PolarityV2':['mean', 'std', 'count']})\n",
    "print(tempRetweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRetweet = dfTweetComm.groupby(['Party','Gen','PartyMentioned']).agg({'PolarityV2':['mean', 'std', 'count']})\n",
    "print(tempRetweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dfTweetComm.groupby(['Party','Gen','PartyMentioned']).agg({'SubjectivityV2':['mean', 'std', 'count']})\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTweetComm.to_csv('C:/Users/kmentzer/Desktop/TweetsMonday.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtag Statistics - 10/9/2019\n",
    "This will loop through each tweet and loop through each hashtag. For each hashtag we will create a new record in the dataframe containing the hashtag, the sentiment of the tweet, whether the tweeter was male/female, and whether the tweeter was dem/rep.\n",
    "This will allow us to create the affective polarization chart for each hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfHashtages = pd.DataFrame()\n",
    "outputFile = open('d:/politics/hashoutnocase.txt', 'w') \n",
    "  \n",
    "for index, row in df.iterrows():\n",
    "#    lv_hashtags = list(row['Hashtags'])\n",
    "    lv_hashtags = str(row['Hashtags']).upper()\n",
    "    lv_hashtags = lv_hashtags.replace('[', '')\n",
    "    lv_hashtags = lv_hashtags.replace(']', '')\n",
    "    lv_hashtags = lv_hashtags.replace('\\'', '')\n",
    "    lv_hashtags = lv_hashtags.replace(',', '')\n",
    "    lv_hashtags = lv_hashtags.split()\n",
    "\n",
    "    lv_sentiment = row['PolarityV2']\n",
    "    lv_gender = row['Gender']\n",
    "    lv_party = row['Party']\n",
    "    try: \n",
    "        for i in lv_hashtags:\n",
    "            print(i, lv_sentiment, lv_gender, lv_party, file = outputFile) \n",
    "    except:\n",
    "            print('Error:', i, lv_sentiment, lv_gender, lv_party) \n",
    "\n",
    "outputFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use wordnet to identify the part of speech for each word. If the word is an  adjective then we add it to our file.\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "outputFile = open('d:/politics/adjectives.txt', 'w')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    lv_tweet = str(row['Tweet']).upper()\n",
    "    lv_sentiment = row['PolarityV2']\n",
    "    lv_gender = row['Gender']\n",
    "    lv_party = row['Party']\n",
    "    \n",
    "    for word in lv_tweet.split():\n",
    "        try:\n",
    "            tmp = wn.synsets(word)[0].pos()\n",
    "        except:\n",
    "            tmp = 'u'\n",
    "        \n",
    "        if tmp == 'a':\n",
    "            print(word, lv_sentiment, lv_gender, lv_party, file = outputFile)\n",
    "\n",
    "            \n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the use ov Vader sentiment versus Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "lv_sent = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    lv_tweet = str(row['Tweet'])\n",
    "    vs = analyzer.polarity_scores(lv_tweet)\n",
    "    lv_sent.append(vs)\n",
    "    \n",
    "df['VaderSentiment'] = lv_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kmentzer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the list of distinct accounts - used to get current status to test if the accounts have since been banned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             TweetDate Hashtags       TweetID  \\\n",
      "0  2018-09-27 13:42:15       []  1.045308e+18   \n",
      "1  2018-09-27 13:43:09       []  1.045308e+18   \n",
      "2  2018-09-27 13:43:16       []  1.045308e+18   \n",
      "3  2018-09-27 13:44:20       []  1.045308e+18   \n",
      "4  2018-09-27 14:50:55       []  1.045325e+18   \n",
      "\n",
      "                                               Tweet   Gender  Retweet  \\\n",
      "0                @SenGillibrand Due process.. idiot!  unknown      0.0   \n",
      "1  RT @JimMOOR22518645: @SenGillibrand Victims do...  unknown      1.0   \n",
      "2  RT @Frmaza: @JimMOOR22518645 @SenGillibrand Yo...  unknown      1.0   \n",
      "3  @SenGillibrand Then there's this... https://t....  unknown      0.0   \n",
      "4  @SenFeinstein Biden the gift that keeps on giv...  unknown      0.0   \n",
      "\n",
      "   PolarityV2 Party  \n",
      "0   -0.462500     R  \n",
      "1   -0.600000     R  \n",
      "2    0.285714     R  \n",
      "3    0.000000     R  \n",
      "4    0.000000     R  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
